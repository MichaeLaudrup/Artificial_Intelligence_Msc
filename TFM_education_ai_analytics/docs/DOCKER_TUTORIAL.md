<<<<<<< HEAD
# ðŸ³ Tutorial Docker para el TFM â€” GuÃ­a para Dummies

## Â¿Por quÃ© Docker?

Tu proyecto de TFM usa **TensorFlow con GPU (CUDA)**. El problema es que CUDA solo funciona
nativamente en Linux, y tÃº trabajas en Windows. Docker soluciona esto creando un **contenedor
Linux** dentro de tu Windows que tiene acceso directo a tu GPU (RTX 3070).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TU WINDOWS                                 â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CONTENEDOR LINUX (Ubuntu)            â”‚  â”‚
â”‚  â”‚                                       â”‚  â”‚
â”‚  â”‚  â€¢ Python 3.11                        â”‚  â”‚
â”‚  â”‚  â€¢ TensorFlow + CUDA                  â”‚  â”‚
â”‚  â”‚  â€¢ Tus dependencias (pandas, etc.)    â”‚  â”‚
â”‚  â”‚  â€¢ Tu cÃ³digo (montado como volumen)   â”‚  â”‚
â”‚  â”‚                                       â”‚  â”‚
â”‚  â”‚  ðŸ”— Acceso a tu GPU RTX 3070         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                             â”‚
â”‚  VS Code se conecta al contenedor          â”‚
â”‚  como si estuvieras en Linux               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Archivos involucrados (4 piezas del puzzle)

El sistema usa **4 archivos** que trabajan juntos. Piensa en ellos como capas:

| Archivo | Â¿QuÃ© hace? | AnalogÃ­a |
|---------|------------|----------|
| `Dockerfile` | Define cÃ³mo construir la imagen | La **receta** de cocina |
| `docker-compose.yml` | Define cÃ³mo ejecutar el contenedor | Las **instrucciones de servir** |
| `.devcontainer/devcontainer.json` | Conecta VS Code al contenedor | El **puente** entre tu editor y el contenedor |
| `.dockerignore` | Dice quÃ© archivos NO enviar a Docker | La **lista de exclusiÃ³n** |

---

## ðŸ”§ Archivo 1: `Dockerfile` â€” La Receta

```dockerfile
FROM tensorflow/tensorflow:latest-gpu-jupyter
```
**LÃ­nea 1 â€” La imagen base.** Es como decir "empieza con un Ubuntu que ya tiene TensorFlow,
CUDA, y Jupyter instalados". No necesitas instalar nada de eso manualmente.

```dockerfile
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
```
**Variables de entorno.**
- `PYTHONDONTWRITEBYTECODE=1`: Evita que Python cree archivos `.pyc` (basura).
- `PYTHONUNBUFFERED=1`: Los prints de Python salen inmediatamente (Ãºtil para logs).

```dockerfile
WORKDIR /workspace
```
**Directorio de trabajo.** Todos los comandos siguientes se ejecutan desde `/workspace`.
Es como hacer `cd /workspace` al principio.

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    curl \
    git \
    make \
    socat \
    wget \
    && rm -rf /var/lib/apt/lists/*
```
**Paquetes del sistema.** Instalamos herramientas que necesita el contenedor:
- `ca-certificates`: Para conexiones HTTPS seguras.
- `curl` / `wget`: Para que VS Code pueda descargarse su servidor remoto dentro del contenedor.
- `git`: Para control de versiones.
- `make`: Para ejecutar el Makefile del proyecto.
- `socat`: Para que VS Code pueda hacer port-forwarding (tÃºneles de red).
- `rm -rf /var/lib/apt/lists/*`: Limpia la cachÃ© de apt para que la imagen sea mÃ¡s pequeÃ±a.

```dockerfile
COPY pyproject.toml README.md LICENSE ./
COPY educational_ai_analytics ./educational_ai_analytics
```
**Copiamos archivos necesarios.** Para instalar el paquete Python, `flit` (nuestro build system)
necesita:
- `pyproject.toml`: Define el proyecto y sus dependencias.
- `README.md`: Lo usa flit para la descripciÃ³n del paquete.
- `LICENSE`: Referenciado en pyproject.toml.
- `educational_ai_analytics/`: El cÃ³digo fuente del paquete.

> âš ï¸ **No copiamos data, notebooks, models, etc.** porque esos se montan como volumen
> (ver docker-compose.yml). Solo copiamos lo mÃ­nimo para instalar dependencias.

```dockerfile
RUN pip install --upgrade pip && \
    pip install --no-cache-dir .
```
**Instalamos las dependencias Python** definidas en `pyproject.toml` (pandas, numpy, scikit-learn,
etc.). TensorFlow NO estÃ¡ en la lista porque ya viene preinstalado en la imagen base.
- `--no-cache-dir`: No guarda cachÃ© de pip â†’ imagen mÃ¡s pequeÃ±a.

```dockerfile
CMD ["tail", "-f", "/dev/null"]
```
**Comando por defecto.** Mantiene el contenedor vivo sin hacer nada. Es como un
"quÃ©date encendido y espera instrucciones". VS Code luego se conectarÃ¡ y lo usarÃ¡.

---

## ðŸŽ¼ Archivo 2: `docker-compose.yml` â€” Las Instrucciones de Servir

```yaml
services:
  tfm-gpu:               # Nombre del servicio
    build: .              # Construye usando el Dockerfile de esta carpeta
    volumes:
      - .:/workspace      # â­ CLAVE: monta tu carpeta local dentro del contenedor
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]   # â­ Reserva tu GPU NVIDIA
    command: tail -f /dev/null      # Mantener vivo
    restart: unless-stopped         # Se reinicia si se cae
    ports:
      - "8888:8888"                 # Puerto de Jupyter
```

### Lo mÃ¡s importante aquÃ­:

**`volumes: - .:/workspace`** â€” Esto es la MAGIA. Monta tu carpeta del proyecto
de Windows directamente dentro del contenedor en `/workspace`. Significa que:
- Los archivos que edites en Windows **aparecen instantÃ¡neamente** en el contenedor.
- Los archivos que cree el contenedor **aparecen en tu Windows**.
- No necesitas copiar nada manualmente. Es como un espejo.

```
TU WINDOWS:                              CONTENEDOR LINUX:
C:\Users\maike\...\TFM_education...  â†â†’  /workspace
â”œâ”€â”€ data/                            â†â†’  â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/                       â†â†’  â”œâ”€â”€ notebooks/
â”œâ”€â”€ educational_ai_analytics/        â†â†’  â”œâ”€â”€ educational_ai_analytics/
â””â”€â”€ ...                              â†â†’  â””â”€â”€ ...
```

**`deploy.resources.reservations.devices`** â€” Le dice a Docker: "este contenedor necesita
una GPU NVIDIA". Docker Desktop + WSL2 + NVIDIA Container Toolkit se encargan de pasar
tu RTX 3070 al contenedor Linux.

---

## ðŸŒ‰ Archivo 3: `.devcontainer/devcontainer.json` â€” El Puente VS Code â†” Contenedor

```jsonc
{
  "name": "TFM GPU Container",
  "dockerComposeFile": "../docker-compose.yml",   // Usa el docker-compose
  "service": "tfm-gpu",                           // Se conecta a este servicio
  "workspaceFolder": "/workspace",                // Abre esta carpeta al conectar

  "customizations": {
    "vscode": {
      "extensions": [                              // Instala estas extensiones
        "ms-python.python",                        // dentro del contenedor
        "ms-toolsai.jupyter",
        "ms-azuretools.vscode-docker"
      ]
    }
  },

  "postCreateCommand": "cd /workspace && pip install --no-deps -e .",

  "remoteUser": "root"
}
```

### Â¿QuÃ© hace cada cosa?

- **`dockerComposeFile`**: Le dice a VS Code "usa docker-compose.yml para levantar el contenedor".
- **`service: "tfm-gpu"`**: "ConÃ©ctate al servicio llamado tfm-gpu".
- **`workspaceFolder`**: "Cuando abras el editor, Ã¡brelo en /workspace".
- **`extensions`**: Instala Python, Jupyter y Docker extensions **dentro del contenedor**
  (separadas de las que tienes en Windows).
- **`postCreateCommand`**: Se ejecuta despuÃ©s de crear el contenedor. Instala tu paquete
  en modo "editable" (`-e .`) para que los cambios en tu cÃ³digo se reflejen sin reinstalar.
  `--no-deps` evita reinstalar dependencias que ya estÃ¡n en la imagen.
- **`remoteUser: "root"`**: Usa el usuario root dentro del contenedor (mÃ¡s simple para desarrollo).

---

## ðŸš« Archivo 4: `.dockerignore` â€” La Lista de ExclusiÃ³n

```
data
models
notebooks
.git
.venv
...
```

Cuando Docker construye la imagen, envÃ­a todos los archivos de tu carpeta al "Docker daemon"
como **contexto de build**. Sin `.dockerignore`, enviarÃ­a TODO (datos, modelos,
virtualenv, historial git...) lo cual harÃ­a el build lentÃ­simo.

Este archivo dice: "no envÃ­es estas carpetas, no las necesitas para construir la imagen".
No las necesitamos porque se montan como volumen despuÃ©s.

---

## ðŸ”„ Flujo completo: Â¿QuÃ© pasa cuando haces "Reopen in Container"?

```
TÃº pulsas "Reopen in Container"
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. BUILD     â”‚  Docker lee el Dockerfile y construye la imagen
    â”‚              â”‚  (instala paquetes, dependencias Python, etc.)
    â”‚              â”‚  Solo tarda la primera vez. DespuÃ©s usa cachÃ©.
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 2. CREATE    â”‚  Docker crea el contenedor usando docker-compose.yml
    â”‚              â”‚  (monta volÃºmenes, reserva GPU, abre puertos)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. START     â”‚  Docker arranca el contenedor
    â”‚              â”‚  (ejecuta "tail -f /dev/null" para mantenerlo vivo)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 4. CONNECT   â”‚  VS Code instala su servidor remoto dentro del
    â”‚              â”‚  contenedor (necesita wget + socat)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 5. POST      â”‚  Ejecuta postCreateCommand:
    â”‚    CREATE     â”‚  "pip install --no-deps -e ." â†’ instala tu paquete
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 6. READY âœ…  â”‚  VS Code abre tu workspace dentro del contenedor
    â”‚              â”‚  Â¡Ya estÃ¡s en Linux con GPU!
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Comandos Ãºtiles

| QuÃ© quieres hacer | Comando |
|---|---|
| Ver contenedores activos | `docker ps` |
| Ver logs del contenedor | `docker logs tfm_education_ai_analytics-tfm-gpu-1` |
| Entrar al contenedor manualmente | `docker exec -it tfm_education_ai_analytics-tfm-gpu-1 bash` |
| Parar todo | `docker compose down` |
| Parar y borrar imagen | `docker compose down --rmi all` |
| Reconstruir desde cero | `docker compose build --no-cache` |
| Verificar GPU dentro del contenedor | `nvidia-smi` (desde la terminal del contenedor) |

---

## â“ Problemas que tuvimos y por quÃ©

| Error | Causa | SoluciÃ³n |
|-------|-------|----------|
| `README.md does not exist` | El Dockerfile solo copiaba `pyproject.toml`, pero `flit` necesita tambiÃ©n README.md y LICENSE | AÃ±adir `COPY README.md LICENSE ./` |
| `Error need wget to download server binary` | VS Code necesita descargar su servidor dentro del contenedor | AÃ±adir `wget` al `apt-get install` |
| `subprocess terminated with return code 127` | VS Code necesita `socat` para port-forwarding | AÃ±adir `socat` al `apt-get install` |
| `file:///root does not appear to be a Python project` | `postCreateCommand` se ejecutaba en `/root` en vez de `/workspace` | Cambiar a `cd /workspace && pip install ...` |
| Build muy lento | Sin `.dockerignore`, Docker enviaba data, .venv, .git, etc. | Crear `.dockerignore` |
| pip tardaba siglos | `tensorflow` estaba en `pyproject.toml` pero ya viene en la imagen base | Quitarlo de las dependencias |
=======
# ðŸ³ Tutorial Docker para el TFM â€” GuÃ­a para Dummies

## Â¿Por quÃ© Docker?

Tu proyecto de TFM usa **TensorFlow con GPU (CUDA)**. El problema es que CUDA solo funciona
nativamente en Linux, y tÃº trabajas en Windows. Docker soluciona esto creando un **contenedor
Linux** dentro de tu Windows que tiene acceso directo a tu GPU (RTX 3070).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TU WINDOWS                                 â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  CONTENEDOR LINUX (Ubuntu)            â”‚  â”‚
â”‚  â”‚                                       â”‚  â”‚
â”‚  â”‚  â€¢ Python 3.11                        â”‚  â”‚
â”‚  â”‚  â€¢ TensorFlow + CUDA                  â”‚  â”‚
â”‚  â”‚  â€¢ Tus dependencias (pandas, etc.)    â”‚  â”‚
â”‚  â”‚  â€¢ Tu cÃ³digo (montado como volumen)   â”‚  â”‚
â”‚  â”‚                                       â”‚  â”‚
â”‚  â”‚  ðŸ”— Acceso a tu GPU RTX 3070         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                             â”‚
â”‚  VS Code se conecta al contenedor          â”‚
â”‚  como si estuvieras en Linux               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Archivos involucrados (4 piezas del puzzle)

El sistema usa **4 archivos** que trabajan juntos. Piensa en ellos como capas:

| Archivo | Â¿QuÃ© hace? | AnalogÃ­a |
|---------|------------|----------|
| `Dockerfile` | Define cÃ³mo construir la imagen | La **receta** de cocina |
| `docker-compose.yml` | Define cÃ³mo ejecutar el contenedor | Las **instrucciones de servir** |
| `.devcontainer/devcontainer.json` | Conecta VS Code al contenedor | El **puente** entre tu editor y el contenedor |
| `.dockerignore` | Dice quÃ© archivos NO enviar a Docker | La **lista de exclusiÃ³n** |

---

## ðŸ”§ Archivo 1: `Dockerfile` â€” La Receta

```dockerfile
FROM tensorflow/tensorflow:latest-gpu-jupyter
```
**LÃ­nea 1 â€” La imagen base.** Es como decir "empieza con un Ubuntu que ya tiene TensorFlow,
CUDA, y Jupyter instalados". No necesitas instalar nada de eso manualmente.

```dockerfile
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
```
**Variables de entorno.**
- `PYTHONDONTWRITEBYTECODE=1`: Evita que Python cree archivos `.pyc` (basura).
- `PYTHONUNBUFFERED=1`: Los prints de Python salen inmediatamente (Ãºtil para logs).

```dockerfile
WORKDIR /workspace
```
**Directorio de trabajo.** Todos los comandos siguientes se ejecutan desde `/workspace`.
Es como hacer `cd /workspace` al principio.

```dockerfile
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    curl \
    git \
    make \
    socat \
    wget \
    && rm -rf /var/lib/apt/lists/*
```
**Paquetes del sistema.** Instalamos herramientas que necesita el contenedor:
- `ca-certificates`: Para conexiones HTTPS seguras.
- `curl` / `wget`: Para que VS Code pueda descargarse su servidor remoto dentro del contenedor.
- `git`: Para control de versiones.
- `make`: Para ejecutar el Makefile del proyecto.
- `socat`: Para que VS Code pueda hacer port-forwarding (tÃºneles de red).
- `rm -rf /var/lib/apt/lists/*`: Limpia la cachÃ© de apt para que la imagen sea mÃ¡s pequeÃ±a.

```dockerfile
COPY pyproject.toml README.md LICENSE ./
COPY educational_ai_analytics ./educational_ai_analytics
```
**Copiamos archivos necesarios.** Para instalar el paquete Python, `flit` (nuestro build system)
necesita:
- `pyproject.toml`: Define el proyecto y sus dependencias.
- `README.md`: Lo usa flit para la descripciÃ³n del paquete.
- `LICENSE`: Referenciado en pyproject.toml.
- `educational_ai_analytics/`: El cÃ³digo fuente del paquete.

> âš ï¸ **No copiamos data, notebooks, models, etc.** porque esos se montan como volumen
> (ver docker-compose.yml). Solo copiamos lo mÃ­nimo para instalar dependencias.

```dockerfile
RUN pip install --upgrade pip && \
    pip install --no-cache-dir .
```
**Instalamos las dependencias Python** definidas en `pyproject.toml` (pandas, numpy, scikit-learn,
etc.). TensorFlow NO estÃ¡ en la lista porque ya viene preinstalado en la imagen base.
- `--no-cache-dir`: No guarda cachÃ© de pip â†’ imagen mÃ¡s pequeÃ±a.

```dockerfile
CMD ["tail", "-f", "/dev/null"]
```
**Comando por defecto.** Mantiene el contenedor vivo sin hacer nada. Es como un
"quÃ©date encendido y espera instrucciones". VS Code luego se conectarÃ¡ y lo usarÃ¡.

---

## ðŸŽ¼ Archivo 2: `docker-compose.yml` â€” Las Instrucciones de Servir

```yaml
services:
  tfm-gpu:               # Nombre del servicio
    build: .              # Construye usando el Dockerfile de esta carpeta
    volumes:
      - .:/workspace      # â­ CLAVE: monta tu carpeta local dentro del contenedor
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]   # â­ Reserva tu GPU NVIDIA
    command: tail -f /dev/null      # Mantener vivo
    restart: unless-stopped         # Se reinicia si se cae
    ports:
      - "8888:8888"                 # Puerto de Jupyter
```

### Lo mÃ¡s importante aquÃ­:

**`volumes: - .:/workspace`** â€” Esto es la MAGIA. Monta tu carpeta del proyecto
de Windows directamente dentro del contenedor en `/workspace`. Significa que:
- Los archivos que edites en Windows **aparecen instantÃ¡neamente** en el contenedor.
- Los archivos que cree el contenedor **aparecen en tu Windows**.
- No necesitas copiar nada manualmente. Es como un espejo.

```
TU WINDOWS:                              CONTENEDOR LINUX:
C:\Users\maike\...\TFM_education...  â†â†’  /workspace
â”œâ”€â”€ data/                            â†â†’  â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/                       â†â†’  â”œâ”€â”€ notebooks/
â”œâ”€â”€ educational_ai_analytics/        â†â†’  â”œâ”€â”€ educational_ai_analytics/
â””â”€â”€ ...                              â†â†’  â””â”€â”€ ...
```

**`deploy.resources.reservations.devices`** â€” Le dice a Docker: "este contenedor necesita
una GPU NVIDIA". Docker Desktop + WSL2 + NVIDIA Container Toolkit se encargan de pasar
tu RTX 3070 al contenedor Linux.

---

## ðŸŒ‰ Archivo 3: `.devcontainer/devcontainer.json` â€” El Puente VS Code â†” Contenedor

```jsonc
{
  "name": "TFM GPU Container",
  "dockerComposeFile": "../docker-compose.yml",   // Usa el docker-compose
  "service": "tfm-gpu",                           // Se conecta a este servicio
  "workspaceFolder": "/workspace",                // Abre esta carpeta al conectar

  "customizations": {
    "vscode": {
      "extensions": [                              // Instala estas extensiones
        "ms-python.python",                        // dentro del contenedor
        "ms-toolsai.jupyter",
        "ms-azuretools.vscode-docker"
      ]
    }
  },

  "postCreateCommand": "cd /workspace && pip install --no-deps -e .",

  "remoteUser": "root"
}
```

### Â¿QuÃ© hace cada cosa?

- **`dockerComposeFile`**: Le dice a VS Code "usa docker-compose.yml para levantar el contenedor".
- **`service: "tfm-gpu"`**: "ConÃ©ctate al servicio llamado tfm-gpu".
- **`workspaceFolder`**: "Cuando abras el editor, Ã¡brelo en /workspace".
- **`extensions`**: Instala Python, Jupyter y Docker extensions **dentro del contenedor**
  (separadas de las que tienes en Windows).
- **`postCreateCommand`**: Se ejecuta despuÃ©s de crear el contenedor. Instala tu paquete
  en modo "editable" (`-e .`) para que los cambios en tu cÃ³digo se reflejen sin reinstalar.
  `--no-deps` evita reinstalar dependencias que ya estÃ¡n en la imagen.
- **`remoteUser: "root"`**: Usa el usuario root dentro del contenedor (mÃ¡s simple para desarrollo).

---

## ðŸš« Archivo 4: `.dockerignore` â€” La Lista de ExclusiÃ³n

```
data
models
notebooks
.git
.venv
...
```

Cuando Docker construye la imagen, envÃ­a todos los archivos de tu carpeta al "Docker daemon"
como **contexto de build**. Sin `.dockerignore`, enviarÃ­a TODO (datos, modelos,
virtualenv, historial git...) lo cual harÃ­a el build lentÃ­simo.

Este archivo dice: "no envÃ­es estas carpetas, no las necesitas para construir la imagen".
No las necesitamos porque se montan como volumen despuÃ©s.

---

## ðŸ”„ Flujo completo: Â¿QuÃ© pasa cuando haces "Reopen in Container"?

```
TÃº pulsas "Reopen in Container"
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. BUILD     â”‚  Docker lee el Dockerfile y construye la imagen
    â”‚              â”‚  (instala paquetes, dependencias Python, etc.)
    â”‚              â”‚  Solo tarda la primera vez. DespuÃ©s usa cachÃ©.
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 2. CREATE    â”‚  Docker crea el contenedor usando docker-compose.yml
    â”‚              â”‚  (monta volÃºmenes, reserva GPU, abre puertos)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. START     â”‚  Docker arranca el contenedor
    â”‚              â”‚  (ejecuta "tail -f /dev/null" para mantenerlo vivo)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 4. CONNECT   â”‚  VS Code instala su servidor remoto dentro del
    â”‚              â”‚  contenedor (necesita wget + socat)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 5. POST      â”‚  Ejecuta postCreateCommand:
    â”‚    CREATE     â”‚  "pip install --no-deps -e ." â†’ instala tu paquete
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 6. READY âœ…  â”‚  VS Code abre tu workspace dentro del contenedor
    â”‚              â”‚  Â¡Ya estÃ¡s en Linux con GPU!
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Comandos Ãºtiles

| QuÃ© quieres hacer | Comando |
|---|---|
| Ver contenedores activos | `docker ps` |
| Ver logs del contenedor | `docker logs tfm_education_ai_analytics-tfm-gpu-1` |
| Entrar al contenedor manualmente | `docker exec -it tfm_education_ai_analytics-tfm-gpu-1 bash` |
| Parar todo | `docker compose down` |
| Parar y borrar imagen | `docker compose down --rmi all` |
| Reconstruir desde cero | `docker compose build --no-cache` |
| Verificar GPU dentro del contenedor | `nvidia-smi` (desde la terminal del contenedor) |

---

## â“ Problemas que tuvimos y por quÃ©

| Error | Causa | SoluciÃ³n |
|-------|-------|----------|
| `README.md does not exist` | El Dockerfile solo copiaba `pyproject.toml`, pero `flit` necesita tambiÃ©n README.md y LICENSE | AÃ±adir `COPY README.md LICENSE ./` |
| `Error need wget to download server binary` | VS Code necesita descargar su servidor dentro del contenedor | AÃ±adir `wget` al `apt-get install` |
| `subprocess terminated with return code 127` | VS Code necesita `socat` para port-forwarding | AÃ±adir `socat` al `apt-get install` |
| `file:///root does not appear to be a Python project` | `postCreateCommand` se ejecutaba en `/root` en vez de `/workspace` | Cambiar a `cd /workspace && pip install ...` |
| Build muy lento | Sin `.dockerignore`, Docker enviaba data, .venv, .git, etc. | Crear `.dockerignore` |
| pip tardaba siglos | `tensorflow` estaba en `pyproject.toml` pero ya viene en la imagen base | Quitarlo de las dependencias |
>>>>>>> c30dc9262eee8dc25b98d7ef8a910c40c00b5fda
