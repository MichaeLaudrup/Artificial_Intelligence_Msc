{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnÃ¡lisis Avanzado de Clustering Estudiantil - TFM\n",
    "\n",
    "Este notebook centraliza la experimentaciÃ³n final de clustering para el proyecto de analÃ­tica educativa OULAD. El objetivo es comparar la calidad de segmentaciÃ³n entre clÃºsteres generados sobre **PCA** frente a los generados sobre el espacio latente del **Autoencoder (AE)**, utilizando diversas tÃ©cnicas de agrupamiento.\n",
    "\n",
    "---\n",
    "**Autor:** TFM Student  \n",
    "**Ãšltima actualizaciÃ³n:** 2026-02-17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ConfiguraciÃ³n del Entorno y Constantes Globales\n",
    "\n",
    "En esta secciÃ³n definimos los parÃ¡metros que rigen todo el notebook (rutas, semillas, parÃ¡metros educativos). Centralizar esto aquÃ­ nos permite cambiar el curso de la investigaciÃ³n (ej. cambiar el nÃºmero de clÃºsteres) desde una Ãºnica celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#         COMUNES\n",
    "# =========================\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Algoritmos y MÃ©tricas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Silenciar ruidos de sistema\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Rutas del proyecto\n",
    "try:\n",
    "    from educational_ai_analytics.config import EMBEDDINGS_DATA_DIR, FEATURES_DATA_DIR, W_WINDOWS\n",
    "    ROOT = Path(EMBEDDINGS_DATA_DIR)\n",
    "    TARGET_PATH = FEATURES_DATA_DIR / \"training\" / \"target.csv\"\n",
    "    WS_TO_PLOT = list(W_WINDOWS)\n",
    "except ImportError:\n",
    "    ROOT = Path(\"/workspace/TFM_education_ai_analytics/data/4_embeddings\")\n",
    "    TARGET_PATH = Path(\"/workspace/TFM_education_ai_analytics/data/3_features/training/target.csv\")\n",
    "    WS_TO_PLOT = [12, 18, 24]\n",
    "\n",
    "# ParÃ¡metros Globales\n",
    "SPLIT = \"training\"\n",
    "K_GLOBAL = 5\n",
    "SEED = 42\n",
    "MAX_POINTS_VIZ = 15000\n",
    "MAX_POINTS_STATS = 5000\n",
    "\n",
    "# Paleta de Colores y Etiquetas OULAD\n",
    "MAP_NUM_TO_STR = {3: \"Distinction\", 2: \"Pass\", 1: \"Fail\", 0: \"Withdrawn\"}\n",
    "OUTCOMES = [\"Distinction\", \"Pass\", \"Fail\", \"Withdrawn\"]\n",
    "OUTCOME_COLORS = {\n",
    "    \"Distinction\": \"#f1c40f\", \n",
    "    \"Pass\": \"#4c78a8\", \n",
    "    \"Fail\": \"#e45756\", \n",
    "    \"Withdrawn\": \"#f4a261\"\n",
    "}\n",
    "\n",
    "def safe_read_csv(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists(): return pd.DataFrame()\n",
    "    return pd.read_csv(path, index_col=0).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# Carga inicial de resultados acadÃ©micos\n",
    "labels_df = pd.read_csv(TARGET_PATH, index_col=0)\n",
    "y_outcome = labels_df[\"final_result\"].map(MAP_NUM_TO_STR)\n",
    "global_success_rate = (labels_df[\"final_result\"] >= 2).mean() * 100\n",
    "\n",
    "print(f\"âœ… ConfiguraciÃ³n cargada. Trabajando con semanas: {WS_TO_PLOT}\")\n",
    "print(f\"ðŸ“Œ Tasa de Ã©xito global: {global_success_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AnÃ¡lisis del NÃºmero Ã“ptimo de ClÃºsteres (K)\n",
    "\n",
    "Antes de aplicar cualquier algoritmo, necesitamos una base empÃ­rica para elegir la cantidad de grupos. AquÃ­ usamos dos criterios:\n",
    "1. **MÃ©todo del Codo (Elbow)**: Buscamos el punto de saturaciÃ³n de la inercia.\n",
    "2. **Silhouette Score**: Evaluamos la cohesiÃ³n y separaciÃ³n media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG-SECTION: ELBOW\n",
    "K_RANGE = range(2, 11)\n",
    "\n",
    "for emb_type in [\"pca\", \"ae\"]:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5), constrained_layout=True)\n",
    "    for W in WS_TO_PLOT:\n",
    "        df = safe_read_csv(ROOT / SPLIT / f\"upto_w{W:02d}\" / f\"{emb_type}_latent.csv\")\n",
    "        if df.empty: continue\n",
    "        if len(df) > MAX_POINTS_STATS: df = df.sample(n=MAX_POINTS_STATS, random_state=SEED)\n",
    "        X = StandardScaler().fit_transform(df.values)\n",
    "        \n",
    "        inerts, silhs = [], []\n",
    "        for k in K_RANGE:\n",
    "            km = KMeans(n_clusters=k, n_init=10, random_state=SEED).fit(X)\n",
    "            inerts.append(km.inertia_)\n",
    "            silhs.append(silhouette_score(X, km.labels_))\n",
    "        \n",
    "        ax1.plot(K_RANGE, inerts, marker='o', label=f\"W{W}\")\n",
    "        ax2.plot(K_RANGE, silhs, marker='s', label=f\"W{W}\")\n",
    "    \n",
    "    ax1.set_title(f\"Elbow Method ({emb_type.upper()})\"); ax1.legend()\n",
    "    ax2.set_title(f\"Silhouette Score ({emb_type.upper()})\"); ax2.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluando la Mixtura de Gaussianas (GMM)\n",
    "\n",
    "El GMM nos permite un modelado probabilÃ­stico mÃ¡s flexible. Para elegir el nÃºmero de componentes, nos basamos en los criterios de informaciÃ³n **BIC (Bayesian Information Criterion)** y **AIC (Akaike)**. El modelo con el BIC mÃ¡s bajo suele ser el que mejor balancea el ajuste frente a la complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG-SECTION: GMM SELECTION\n",
    "COV_TYPE = \"diag\"\n",
    "\n",
    "for emb_type in [\"pca\", \"ae\"]:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    for W in WS_TO_PLOT:\n",
    "        df = safe_read_csv(ROOT / SPLIT / f\"upto_w{W:02d}\" / f\"{emb_type}_latent.csv\")\n",
    "        if df.empty: continue\n",
    "        X = StandardScaler().fit_transform(df.sample(min(len(df), 5000), random_state=SEED))\n",
    "        bics = [GaussianMixture(k, covariance_type=COV_TYPE, random_state=SEED).fit(X).bic(X) for k in K_RANGE]\n",
    "        ax.plot(K_RANGE, bics, marker='o', label=f\"W{W}\")\n",
    "    ax.set_title(f\"BIC Score (GMM {COV_TYPE}) - {emb_type.upper()}\")\n",
    "    ax.set_ylabel(\"BIC Value (Lower is better)\"); ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparativa Cuantitativa de Algoritmos\n",
    "\n",
    "En esta secciÃ³n generamos una comparativa directa entre los tres grandes enfoques: **K-Means** (Particional), **GMM** (ProbabilÃ­stico) y **JerÃ¡rquico** (Ward). Esta tabla nos permite contrastar cientÃ­ficamente cuÃ¡l es el mejor mÃ©todo para segmentar en cada espacio de representaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG-SECTION: METRICS TABLE\n",
    "HIER_LINKAGE = \"ward\"\n",
    "\n",
    "all_metrics = []\n",
    "for W in WS_TO_PLOT:\n",
    "    for emb in [\"pca\", \"ae\"]:\n",
    "        df = safe_read_csv(ROOT / SPLIT / f\"upto_w{W:02d}\" / f\"{emb}_latent.csv\")\n",
    "        if df.empty: continue\n",
    "        X = StandardScaler().fit_transform(df.sample(min(len(df), MAX_POINTS_STATS), random_state=SEED))\n",
    "        \n",
    "        # Ajustar modelos\n",
    "        m_km = KMeans(K_GLOBAL, n_init=10, random_state=SEED).fit_predict(X)\n",
    "        m_gmm = GaussianMixture(K_GLOBAL, covariance_type=\"diag\", random_state=SEED).fit_predict(X)\n",
    "        m_hier = AgglomerativeClustering(K_GLOBAL, linkage=HIER_LINKAGE).fit_predict(X)\n",
    "        \n",
    "        for name, labs in [(\"K-Means\", m_km), (\"GMM\", m_gmm), (\"JerÃ¡rquico\", m_hier)]:\n",
    "            all_metrics.append({\n",
    "                \"Semana\": W, \"Embedding\": emb.upper(), \"Modelo\": name,\n",
    "                \"Silueta\": silhouette_score(X, labs),\n",
    "                \"CH-Score\": calinski_harabasz_score(X, labs),\n",
    "                \"DB-Index\": davies_bouldin_score(X, labs)\n",
    "            })\n",
    "\n",
    "df_res = pd.DataFrame(all_metrics)\n",
    "for emb in [\"PCA\", \"AE\"]:\n",
    "    display(Markdown(f\"### ðŸ† Resultados para: **{emb}**\"))\n",
    "    display(df_res[df_res[\"Embedding\"] == emb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dashboard de Resultados y Desglose Educativo\n",
    "\n",
    "Finalmente, visualizamos los clÃºsteres. El orden de los grupos se ajusta automÃ¡ticamente por su tasa de abandono (**Withdrawn**), de modo que el \"Riesgo 0\" sea siempre el perfil mÃ¡s crÃ­tico. Esto nos permite comparar visualmente la pureza de los grupos entre PCA y AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG-SECTION: VISUALIZATION DASHBOARD\n",
    "MODEL_TO_PLOT = \"GMM\" # Opciones: \"GMM\", \"K-Means\", \"JerÃ¡rquico\"\n",
    "\n",
    "nrows = len(WS_TO_PLOT)\n",
    "fig, axes = plt.subplots(nrows, 4, figsize=(22, 6 * nrows), constrained_layout=True)\n",
    "if nrows == 1: axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "for i, W in enumerate(WS_TO_PLOT):\n",
    "    for j, emb_type in enumerate([\"pca\", \"ae\"]):\n",
    "        df_emb = safe_read_csv(ROOT / SPLIT / f\"upto_w{W:02d}\" / f\"{emb_type}_latent.csv\")\n",
    "        df_join = df_emb.join(y_outcome.rename(\"outcome\"), how=\"inner\")\n",
    "        if len(df_join) > MAX_POINTS_VIZ: df_join = df_join.sample(MAX_POINTS_VIZ, random_state=SEED)\n",
    "        \n",
    "        X = StandardScaler().fit_transform(df_join.drop(columns=[\"outcome\"]).values)\n",
    "        \n",
    "        # Clustering (usamos el seleccionado)\n",
    "        if MODEL_TO_PLOT == \"GMM\": labs = GaussianMixture(K_GLOBAL, random_state=SEED).fit_predict(X)\n",
    "        else: labs = KMeans(K_GLOBAL, random_state=SEED).fit_predict(X)\n",
    "        \n",
    "        # Reordenar por riesgo (Withdrawn rate)\n",
    "        tmp = pd.DataFrame({\"cl\": labs, \"res\": df_join[\"outcome\"]})\n",
    "        rates = tmp.groupby(\"cl\")[\"res\"].apply(lambda x: (x == \"Withdrawn\").mean()).sort_values(ascending=False)\n",
    "        map_risk = {old: f\"R{idx}\" for idx, old in enumerate(rates.index)}\n",
    "        tmp[\"group\"] = tmp[\"cl\"].map(map_risk)\n",
    "        order_g = [map_risk[cl] for cl in rates.index]\n",
    "\n",
    "        # Scatter (PCA view)\n",
    "        Z = PCA(2).fit_transform(X)\n",
    "        ax_sc = axes[i, j*2]\n",
    "        for out in OUTCOMES:\n",
    "            m = df_join[\"outcome\"] == out\n",
    "            ax_sc.scatter(Z[m, 0], Z[m, 1], s=4, c=OUTCOME_COLORS[out], alpha=0.5)\n",
    "        ax_sc.set_title(f\"W{W} {emb_type.upper()} | Scatter (Outcome)\"); ax_sc.axis('off')\n",
    "\n",
    "        # Bars (Dashboard)\n",
    "        ax_bar = axes[i, j*2+1]\n",
    "        tab = pd.crosstab(tmp[\"group\"], tmp[\"res\"], normalize='index') * 100\n",
    "        for o in OUTCOMES: \n",
    "            if o in tab.columns: ax_bar.bar(order_g, tab.reindex(order_g)[o], label=o, color=OUTCOME_COLORS[o])\n",
    "        ax_bar.axhline(global_success_rate, color='k', ls='--')\n",
    "        ax_bar.set_title(f\"Frecuencias W{W} {emb_type.upper()}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
