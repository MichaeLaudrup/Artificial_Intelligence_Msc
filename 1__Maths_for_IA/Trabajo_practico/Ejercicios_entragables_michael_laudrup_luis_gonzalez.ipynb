{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nombre alumno: Michael Laudrup Luis González\n",
    "#### Repositorio GIT asociado: https://github.com/MichaeLaudrup/Maths_for_IA_VIU/tree/main/Trabajo_practico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.a [1 punto] Implementa una función, `determinante_recursivo`, que obtenga el determinante de una matriz cuadrada utilizando la definición recursiva de Laplace.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "\n",
    "def determinante_recursivo(matriz):\n",
    "    matriz = np.array(matriz, dtype=float) \n",
    "    \n",
    "    if matriz.shape[0] == 2 and matriz.shape[1] == 2:\n",
    "        return (matriz[0, 0] * matriz[1, 1]) - (matriz[0, 1] * matriz[1, 0])\n",
    "    else:\n",
    "        row_idx = 0\n",
    "        det = 0.0\n",
    "        for col_idx, ele in enumerate(matriz[row_idx]):\n",
    "            minor = np.delete(np.delete(matriz, 0, axis=0), col_idx, axis=1)\n",
    "            signo = (-1)**(col_idx + row_idx)\n",
    "            det += ele * signo * determinante_recursivo(minor)\n",
    "        return det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.b [0.5 puntos] Si A es una matriz cuadrada $n×n$ y triangular (superior o inferior, es decir, con entradas nulas por debajo o por encima de la diagonal, respectivamente), ¿existe alguna forma de calcular de forma directa y sencilla su determinante? Justifíquese la respuesta.</b>\n",
    "\n",
    "En el caso de nuestro algoritmo anteriormente implementado tenemos que fijarnos en el caso de que la matriz objeto de estudio sea mayor de 2x2  se ejecutará el siguiente código:\n",
    "\n",
    "```\n",
    "    row_idx = 0\n",
    "    det = 0\n",
    "    for col_idx, ele in enumerate(matriz[row_idx]):\n",
    "        minor = np.delete(np.delete(matriz, 0, axis=0), col_idx, axis=1)\n",
    "        det += ele * (-1)**((col_idx+row_idx)) * determinante_recursivo(minor)\n",
    "    return det\n",
    "```\n",
    "\n",
    "Al ser una matriz cuadrada triangular superior o inferior, ya no es necesario el bucle \"for\" sino que bastaría con siempre coger el elemento de la fila que más cero tiene, es decir:\n",
    "\n",
    "- Para una matriz cuadrada triangular superior: Siempre cogeremos el último elemento de la última fila, quedandonos: \n",
    "```\n",
    "row_idx = matriz.shape[0] - 1 # número de filas (cogemos ultima posición)\n",
    "col_idx = matriz.shape[1] - 1 # número de columnas (cogemos última posición)\n",
    "minor = np.delete(np.delete(matriz, row_idx, axis=0), col_idx, axis=1)\n",
    "det = ele * (-1)**((col_idx+row_idx)) * determinante_recursivo(minor)\n",
    "\n",
    "```\n",
    "\n",
    "Lo que apreciaremos es que a medida que vamos bajando en la recursividad, se sucede lo mismo en cadena, por lo que podemos concluir que realmente la operación quedará como la multiplicación de los elementos de la diagonal principal.\n",
    "\n",
    "- Para una matriz cuadrada triangular inferior: Sucederá exactamente lo mismo que el anterior caso, pero en lugar de coger la última posición de la última fila en cada paso recursivo, lo que haremos será coger el primer elemento de la primera fila, por lo que:\n",
    "\n",
    "```\n",
    "row_idx = 0\n",
    "col_idx = 0\n",
    "```\n",
    "\n",
    "En conclusión, para matrices triangulares superiores o inferiores, el determinante se puede calcular directamente como el producto de los elementos de la diagonal principal, ya que todos los menores serán matrices de orden inferior que también son triangulares y su determinante será cero, excepto el último paso recursivo.\n",
    "\n",
    "**Nota importante**: Se ha intentado dar una justificación más asociada a la implementación especifica de este algoritmo para aportar un razonamiento diferente al que se suele dar en los libros de texto, pero la justificación general es la misma, ya que al final el determinante de una matriz triangular superior o inferior es el producto de los elementos de la diagonal principal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.c [0.5 puntos] Determínese de forma justificada cómo alteran el determinante de una matriz $n \\times n$ las dos operaciones elementales siguientes: </b>\n",
    "\n",
    "- <b>Intercambiar una fila (o columna) por otra fila (o columna): </b> En este caso cada vez que intercambiamos filas o columnas invertimos el signo del determinante. Un ejemplo sencillo se puede ver con una matriz 2x2, si tenemos la matriz:\n",
    "$$\n",
    "A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} \\quad \\rightarrow \\quad \\det(A) = ad - bc\n",
    "$$\n",
    "\n",
    "Luego, si intercambiamos las filas, obtenemos:\n",
    "\n",
    "$$\n",
    "A' = \\begin{pmatrix} c & d \\\\ a & b \\end{pmatrix} \\quad \\rightarrow \\quad \\det(A') = cb - da = -(ad - bc) = -\\det(A)\n",
    "$$\n",
    "\n",
    "Para el caso de matrices mayores, el efecto es el mismo.\n",
    "\n",
    "- <b>Suma a una fila (o columna) otra fila ( o columna) multiplicada por un escalar $\\alpha$ :</b> Al final estas operaciones lo que hacen es darnos una combinación lineal del vector fila o vector columna sobre el que aplicamos la operación, es decir, que realmente estaríamos obteniendo un vector equivalente por lo que no estaríamos perdiendo ni ganando información, solo transformandola, entonces matemáticamente hablando siguen siendo los mismos vectores, esto se extrapolará en el calculo del determinante, el cual, no se verá alterado por esta operación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.d [1 punto] Investiga sobre el método de eliminación de Gauss con pivoteo parcial e impleméntalo para escalonar una matriz (es decir, convertirla en una matriz triangular inferior) a partir de las operaciones elementales descritas en el apartado anterior.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.41428571,  0.        ,  0.        , -0.5       ],\n",
       "        [ 0.2       , -0.7       ,  0.        , -0.3       ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ]]),\n",
       " 0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matriz_B = np.array([[4, 2, 3],\n",
    "            [4, 13, 6],\n",
    "            [7, 8, 9]])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "matriz_B = np.array([[4, 2, 3],\n",
    "                     [4, 13, 6],\n",
    "                     [7, 8, 9]])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gauss_elimination(matrix):\n",
    "    \"\"\"\n",
    "    Triangulariza inferiormente la matriz y devuelve el número de intercambios realizados.\n",
    "    \"\"\"\n",
    "    A = np.array(matrix, dtype=float)\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    if n <= 1:\n",
    "        return A, 0\n",
    "\n",
    "    swaps = 0\n",
    "    pivot_col = n - 1\n",
    "    max_row = np.argmax(np.abs(A[:, pivot_col]))\n",
    "\n",
    "    if max_row != n - 1:\n",
    "        A[[n - 1, max_row]] = A[[max_row, n - 1]]\n",
    "        swaps = 1\n",
    "\n",
    "    if abs(A[n - 1, n - 1]) > 1e-12:\n",
    "        for row_idx in range(n - 1):\n",
    "            factor = A[row_idx, n - 1] / A[n - 1, n - 1]\n",
    "            A[row_idx] = A[row_idx] - (A[n - 1] * factor)\n",
    "\n",
    "    sub_matrix = A[:-1, :-1]\n",
    "    triangulated_sub_matrix, lower_level_swaps = gauss_elimination(sub_matrix)\n",
    "\n",
    "    A[:-1, :-1] = triangulated_sub_matrix\n",
    "    total_swaps = swaps + lower_level_swaps\n",
    "    \n",
    "    return A, total_swaps\n",
    "\n",
    "gauss_elimination(matriz_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solución [-3.5  2.   2.5]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0.2, 0.1, 0.5],\n",
    "              [0.5, 0.6, 0.3],\n",
    "              [0.3, 0.3, .20]], dtype=float)\n",
    "b = np.array([0.75, 0.2, 0.05])\n",
    "\n",
    "sol = np.linalg.solve(A, b)\n",
    "\n",
    "print(\"Solución\", sol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.e [0.5 puntos] ¿Cómo se podría calcular el determinante de una matriz haciendo beneficio de la estrategia anterior y del efecto de aplicar las operaciones elementales pertinentes? Implementa una nueva función, `determinante gauss`, que calcule el determinante de una matriz utilizando eliminación gaussiana.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determinante_gauss(matriz):\n",
    "    matriz = np.array(matriz, dtype=float) \n",
    "    if(matriz.shape[0] == 2 and matriz.shape[1] == 2):\n",
    "        return (matriz[0][0] * matriz[1][1]) - (matriz[0][1] * matriz[1][0])\n",
    "    \n",
    "    matriz, total_swaps = gauss_elimination(matriz)\n",
    "    det = 1\n",
    "    for i in range(matriz.shape[0]):\n",
    "        det *= matriz[i][i]\n",
    "    \n",
    "    return det * (-1)**total_swaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.f [0.5 puntos] Obtén la complejidad computacional asociada al cálculo del determinante con la definición recursiva y con el método de eliminación de Gauss con pivoteo parcial.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Coste computacional determinante recursivo</b>\n",
    "\n",
    "En el caso de la función `determinante_recursivo`, tenemos que:\n",
    "\n",
    "- El caso base tiene coste $O(1)$, ya que simplemente devuelve un valor.\n",
    "- Para una matriz $n \\times n$, el bucle `for` itera $n$ veces, y en cada iteración se llama recursivamente a `determinante_recursivo` con una matriz de tamaño $(n-1) \\times (n-1)$. Por lo tanto, la relación de recurrencia es:\n",
    "$$ T(n) = n \\cdot T(n-1) + operaciones_adicionales$$\n",
    "\n",
    "Entiendosé como operaciones, por ejemplo, `np.delete` que tiene un coste de $O(n^2)$, sin embargo, el término dominante proviene de las llamadas recursivas. En esta recursividad tenemos que:\n",
    "\n",
    "- Para $T(n)$, hacemos $n$ llamadas a $T(n-1)$ -> $T(n) = n \\cdot T(n-1)$\n",
    "- Para $T(n-1)$, hacemos $(n-1)$ llamadas a $T(n-2)$ -> $T(n-1) = (n-1) \\cdot T(n-2)$\n",
    "- Y así sucesivamente hasta llegar al caso base $T(2)$. -> $T(n) = n \\cdot (n-1) \\cdot (n-2) \\cdot \\dots \\cdot 3 \\cdot T(2)$\n",
    "\n",
    "De todo esto podemos concluir que el coste total de la función `determinante_recursivo` es $O(n!)$, ya que el número de llamadas recursivas crece factorialmente con el tamaño de la matriz.\n",
    "\n",
    "--- \n",
    "<b>Coste computacional determinante gaussiano</b>\n",
    "\n",
    "La complejidad del algoritmo determinante_gauss está casi enteramente determinada por el coste de la función gauss_elimination. Una vez que la matriz está en su forma triangular superior, calcular el determinante es muy rápido (un solo bucle de coste O(n))\n",
    "\n",
    "Analicemos la complejidad de `gauss_elimination`:\n",
    "- La función se llama a sí misma recursivamente con una matriz cada vez más pequeña, va primero con $n$, luego con $n-1$, y así sucesivamente\n",
    "- En cada llamada hay un bucle for especializado en poner a cero los elementos de la primera columna, ejecutandose  $k -1$ veces\n",
    "- Dentro del bucle la línea `A[row_idx] = A[row_idx] - (A[0] * factor)` realiza una operación vectorial con coste $O(k)$.\n",
    "- Por lo tanto, la primera parte de la función `gauss_elimination` tiene un coste de $O(k^2)$, ya que se ejecuta $k-1$ veces y cada vez realiza una operación de coste $O(k)$.\n",
    "- Tras esto se realiza una llamada recursiva a `gauss_elimination` con una matriz de tamaño $k-1$, lo que nos da la relación de recurrencia:\n",
    "$$ T(k) = O(k^2) + T(k-1) $$\n",
    "\n",
    "- Al expandir esta relación, obtenemos:\n",
    "$$ T(k) = O(k^2) + O((k-1)^2) + O((k-2)^2) + \\ldots + O(1^2) $$\n",
    "\n",
    "La suma de los cuadrados de los primeros $k$ números es conocida y se puede expresar como:\n",
    "$$ \\sum_{i=1}^{k} i^2 = \\frac{k(k+1)(2k+1)}{6} $$\n",
    "\n",
    "Por lo tanto, la complejidad total de `gauss_elimination` es:\n",
    "$$ T(k) = O(k^3) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.g [1 punto] Utilizando `numpy.random.rand`, genera matrices cuadradas aleatorias de la forma $A_n \\in \\mathbb{R}^{n \\times n}$, para $2 \\le n \\le 10$, y confecciona una tabla comparativa del tiempo de ejecución asociado a cada una de las variantes siguientes, interpretando los resultados:</b>\n",
    "\n",
    "* Utilizando `determinante_recursivo`.\n",
    "* Empleando `determinante_gauss`.\n",
    "* Haciendo uso de la función preprogramada `numpy.linalg.det`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test #1 - Tamaño: 8x8\n",
      "Matriz:\n",
      " [[  9   4   0  -3  10  -4   8   0]\n",
      " [  0  10  -7  -3  -8  10  -9   1]\n",
      " [ -5  -9  10 -10   1   1   6  -1]\n",
      " [  5   4   4   8   1   9  -8  -6]\n",
      " [  8  -4  10  -2  -4   7  -7   3]\n",
      " [  7  -2  10  -9   9   4  -4   1]\n",
      " [ -3   4  -8   3   6  -7   7  -3]\n",
      " [ -7  -9  -5  -1  -7   7   1  -9]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 231186.40 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 86.90 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 232.80 microsegundos\n",
      "Determinante (recursivo): -17134792.0\n",
      "Determinante (Gauss):     -17134792.000000\n",
      "Determinante (NumPy):     -17134792.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #2 - Tamaño: 5x5\n",
      "Matriz:\n",
      " [[  3   5   4  -3   3]\n",
      " [ -3  10   5   2   7]\n",
      " [  4  10   2  -2   4]\n",
      " [  2 -10  -4  -2 -10]\n",
      " [  1  -3   0   8   6]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 725.00 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 15.70 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 110.80 microsegundos\n",
      "Determinante (recursivo): -7584.0\n",
      "Determinante (Gauss):     -7584.000000\n",
      "Determinante (NumPy):     -7584.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #3 - Tamaño: 9x9\n",
      "Matriz:\n",
      " [[ -8  -8 -10  -6  -1  -4  -2  -4  -2]\n",
      " [ -3   1  -9 -10   5  -6  -8   1  -3]\n",
      " [ -8 -10  -8  -6   4   3  -8 -10  -6]\n",
      " [  3  -4  -2   4   4  -1   2   8  -4]\n",
      " [  6   9  -7  -6  -4   2   4   0  -7]\n",
      " [  2  -4   8  -9  -1   2  10  -5   1]\n",
      " [  1   9   0  -4 -10 -10   9   2  -2]\n",
      " [ -8  -4  -5  -3  -2  -6 -10   8  -1]\n",
      " [  1   4  -2   9   6   6   9   1  -4]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 2076369.00 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 63.30 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 275.10 microsegundos\n",
      "Determinante (recursivo): 4412290442.0\n",
      "Determinante (Gauss):     4412290442.000001\n",
      "Determinante (NumPy):     4412290442.000013\n",
      "❌ Diferencia significativa\n",
      "\n",
      "Test #4 - Tamaño: 3x3\n",
      "Matriz:\n",
      " [[-8  6 -6]\n",
      " [ 6  6  6]\n",
      " [-9 -9 -6]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 68.00 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 29.10 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 353.80 microsegundos\n",
      "Determinante (recursivo): -252.0\n",
      "Determinante (Gauss):     -252.000000\n",
      "Determinante (NumPy):     -252.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #5 - Tamaño: 2x2\n",
      "Matriz:\n",
      " [[-10   8]\n",
      " [ -9  10]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 4.60 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 29.60 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 3.40 microsegundos\n",
      "Determinante (recursivo): -28.0\n",
      "Determinante (Gauss):     -28.000000\n",
      "Determinante (NumPy):     -28.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #6 - Tamaño: 7x7\n",
      "Matriz:\n",
      " [[ -7   0   6  -5  -6   9  -9]\n",
      " [ -5   0   5   5 -10  -2  -5]\n",
      " [  5  -8   9  -7   8  -8   8]\n",
      " [  9  -4   9  -2 -10  -3  -4]\n",
      " [  7  -3 -10   0   7  -1  -8]\n",
      " [ -4   5   5   9   6  -9 -10]\n",
      " [  5   1  -6  -6  -2  -2  -8]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 28665.20 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 42.60 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 144.70 microsegundos\n",
      "Determinante (recursivo): 59302125.0\n",
      "Determinante (Gauss):     59302125.000000\n",
      "Determinante (NumPy):     59302125.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #7 - Tamaño: 4x4\n",
      "Matriz:\n",
      " [[  5   5  -8   9]\n",
      " [-10   9   0   6]\n",
      " [ -3  -7  -5  -3]\n",
      " [  9  -8   5  -8]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 153.10 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 15.60 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 57.80 microsegundos\n",
      "Determinante (recursivo): -189.0\n",
      "Determinante (Gauss):     -189.000000\n",
      "Determinante (NumPy):     -189.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #8 - Tamaño: 10x10\n",
      "Matriz:\n",
      " [[  7   3   7  -9  -8   5  -2  -7 -10  -7]\n",
      " [-10   3  10   5   9  -3  -4  -8   6 -10]\n",
      " [  5   1   8   3  -5  -5   2   8  -3  -9]\n",
      " [ 10 -10   4 -10  -6   5   8  -7  -8   6]\n",
      " [  6   1   3  10  -5  -8  -2  -6   6   3]\n",
      " [ 10  -8 -10   9  10 -10  -8   7  -1  -8]\n",
      " [ -3   3   7   4  -9  -1  -9   6  -3 -10]\n",
      " [ -2   0   5  -4  -1  -8   7   2  -4  -7]\n",
      " [  2   9 -10  -3   3   5   3   1   8   4]\n",
      " [ -9  -9   8   6   9  -1  -5   4   0  -6]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 20636670.20 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 48.70 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 258.90 microsegundos\n",
      "Determinante (recursivo): 23302844006.0\n",
      "Determinante (Gauss):     23302844006.000004\n",
      "Determinante (NumPy):     23302844005.999950\n",
      "❌ Diferencia significativa\n",
      "\n",
      "Test #9 - Tamaño: 2x2\n",
      "Matriz:\n",
      " [[-3 10]\n",
      " [ 1  1]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 4.90 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 13.00 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 3.70 microsegundos\n",
      "Determinante (recursivo): -13.0\n",
      "Determinante (Gauss):     -13.000000\n",
      "Determinante (NumPy):     -13.000000\n",
      "✅ Resultado correcto\n",
      "\n",
      "Test #10 - Tamaño: 6x6\n",
      "Matriz:\n",
      " [[ -4  -7  -5   2   9   4]\n",
      " [ -8  -3   9   5   2   7]\n",
      " [ -1   8   6   8  -6  10]\n",
      " [ -2   1  10 -10 -10   4]\n",
      " [ -9   5  -3   2  10 -10]\n",
      " [  5  -4  -6  -8   1   5]]\n",
      "[determinante_recursivo] Tiempo de ejecución promedio en 1 iteraciones: 4338.90 microsegundos\n",
      "[det] Tiempo de ejecución promedio en 1 iteraciones: 19.60 microsegundos\n",
      "[determinante_gauss] Tiempo de ejecución promedio en 1 iteraciones: 102.30 microsegundos\n",
      "Determinante (recursivo): -858435.0\n",
      "Determinante (Gauss):     -858435.000000\n",
      "Determinante (NumPy):     -858435.000000\n",
      "✅ Resultado correcto\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tamaño</th>\n",
       "      <th>Determinante (Recursivo)</th>\n",
       "      <th>Determinante (Gauss)</th>\n",
       "      <th>Determinante (NumPy)</th>\n",
       "      <th>Tiempo Recursivo</th>\n",
       "      <th>Tiempo Gauss</th>\n",
       "      <th>Tiempo NumPy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.713479e+07</td>\n",
       "      <td>-1.713479e+07</td>\n",
       "      <td>-1.713479e+07</td>\n",
       "      <td>2.311864e+05</td>\n",
       "      <td>232.799988</td>\n",
       "      <td>86.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>-7.584000e+03</td>\n",
       "      <td>-7.584000e+03</td>\n",
       "      <td>-7.584000e+03</td>\n",
       "      <td>7.250000e+02</td>\n",
       "      <td>110.799988</td>\n",
       "      <td>15.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4.412290e+09</td>\n",
       "      <td>4.412290e+09</td>\n",
       "      <td>4.412290e+09</td>\n",
       "      <td>2.076369e+06</td>\n",
       "      <td>275.099976</td>\n",
       "      <td>63.299927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.520000e+02</td>\n",
       "      <td>-2.520000e+02</td>\n",
       "      <td>-2.520000e+02</td>\n",
       "      <td>6.800000e+01</td>\n",
       "      <td>353.800049</td>\n",
       "      <td>29.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.800000e+01</td>\n",
       "      <td>-2.800000e+01</td>\n",
       "      <td>-2.800000e+01</td>\n",
       "      <td>4.600037e+00</td>\n",
       "      <td>3.400024</td>\n",
       "      <td>29.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5.930212e+07</td>\n",
       "      <td>5.930213e+07</td>\n",
       "      <td>5.930212e+07</td>\n",
       "      <td>2.866520e+04</td>\n",
       "      <td>144.700012</td>\n",
       "      <td>42.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.890000e+02</td>\n",
       "      <td>-1.890000e+02</td>\n",
       "      <td>-1.890000e+02</td>\n",
       "      <td>1.531000e+02</td>\n",
       "      <td>57.800049</td>\n",
       "      <td>15.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>2.330284e+10</td>\n",
       "      <td>2.330284e+10</td>\n",
       "      <td>2.330284e+10</td>\n",
       "      <td>2.063667e+07</td>\n",
       "      <td>258.899963</td>\n",
       "      <td>48.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.300000e+01</td>\n",
       "      <td>-1.300000e+01</td>\n",
       "      <td>-1.300000e+01</td>\n",
       "      <td>4.899963e+00</td>\n",
       "      <td>3.700012</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>-8.584350e+05</td>\n",
       "      <td>-8.584350e+05</td>\n",
       "      <td>-8.584350e+05</td>\n",
       "      <td>4.338900e+03</td>\n",
       "      <td>102.299988</td>\n",
       "      <td>19.599976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tamaño  Determinante (Recursivo)  Determinante (Gauss)  \\\n",
       "0       8             -1.713479e+07         -1.713479e+07   \n",
       "1       5             -7.584000e+03         -7.584000e+03   \n",
       "2       9              4.412290e+09          4.412290e+09   \n",
       "3       3             -2.520000e+02         -2.520000e+02   \n",
       "4       2             -2.800000e+01         -2.800000e+01   \n",
       "5       7              5.930212e+07          5.930213e+07   \n",
       "6       4             -1.890000e+02         -1.890000e+02   \n",
       "7      10              2.330284e+10          2.330284e+10   \n",
       "8       2             -1.300000e+01         -1.300000e+01   \n",
       "9       6             -8.584350e+05         -8.584350e+05   \n",
       "\n",
       "   Determinante (NumPy)  Tiempo Recursivo  Tiempo Gauss  Tiempo NumPy  \n",
       "0         -1.713479e+07      2.311864e+05    232.799988     86.900024  \n",
       "1         -7.584000e+03      7.250000e+02    110.799988     15.700012  \n",
       "2          4.412290e+09      2.076369e+06    275.099976     63.299927  \n",
       "3         -2.520000e+02      6.800000e+01    353.800049     29.099976  \n",
       "4         -2.800000e+01      4.600037e+00      3.400024     29.599976  \n",
       "5          5.930212e+07      2.866520e+04    144.700012     42.599976  \n",
       "6         -1.890000e+02      1.531000e+02     57.800049     15.599976  \n",
       "7          2.330284e+10      2.063667e+07    258.899963     48.700012  \n",
       "8         -1.300000e+01      4.899963e+00      3.700012     13.000000  \n",
       "9         -8.584350e+05      4.338900e+03    102.299988     19.599976  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def control_time_execution(function, matrix, n = 1):\n",
    "    \"\"\" Imprime el tiempo de ejecución promedio de una función dada, ejecutándola n veces\n",
    "\n",
    "    Keyword arguments:\n",
    "    function -- función a medir\n",
    "    n -- número de iteraciones (default 100)\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    for _ in range(n):\n",
    "        start = time.perf_counter() * 1000000\n",
    "        result = function(matrix)\n",
    "        end = time.perf_counter() * 1000000\n",
    "        acc += ((end -start))\n",
    "    mean_time = acc / n\n",
    "    print(f\"[{function.__name__}] Tiempo de ejecución promedio en {n} iteraciones: {(mean_time):.2f} microsegundos\")\n",
    "    return result, mean_time\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "n_pruebas = 10\n",
    "min_size = 2\n",
    "max_size = 10\n",
    "tolerancia = 1e-6\n",
    "\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for i in range(n_pruebas):\n",
    "    size = np.random.randint(min_size, max_size + 1)\n",
    "    matrix = np.random.randint(-10, 11, size=(size, size))\n",
    "    print(f\"Test #{i+1} - Tamaño: {size}x{size}\")\n",
    "    print(\"Matriz:\\n\", matrix)\n",
    "\n",
    "    det_recursivo, rec_t = control_time_execution(determinante_recursivo, matrix)\n",
    "    det_numpy, np_t = control_time_execution(np.linalg.det, matrix)\n",
    "    det_gauss, gauss_t = control_time_execution(determinante_gauss, matrix.copy())\n",
    "\n",
    "    resultados.append([\n",
    "        size,\n",
    "        det_recursivo,\n",
    "        det_gauss,\n",
    "        det_numpy,\n",
    "        rec_t,\n",
    "        gauss_t,\n",
    "        np_t\n",
    "    ])\n",
    "\n",
    "    print(f\"Determinante (recursivo): {det_recursivo}\")\n",
    "    print(f\"Determinante (Gauss):     {det_gauss:.6f}\")\n",
    "    print(f\"Determinante (NumPy):     {det_numpy:.6f}\")\n",
    "    if abs(det_recursivo - det_numpy) < tolerancia:\n",
    "        print(\"✅ Resultado correcto\\n\")\n",
    "    else:\n",
    "        print(\"❌ Diferencia significativa\\n\")\n",
    "times_execution = pd.DataFrame(\n",
    "    columns=[\"Tamaño\", \"Determinante (Recursivo)\", \"Determinante (Gauss)\", \"Determinante (NumPy)\", \"Tiempo Recursivo\", \"Tiempo Gauss\", \"Tiempo NumPy\"],\n",
    "    data=resultados)\n",
    "\n",
    "display(times_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Interpretación de resultados:</b>\n",
    "\n",
    "Lo que podemos apreciar es que el algoritmo de eliminación de Gauss ha demostrado ser significativamente más eficiente que el método recursivo para calcular el determinante, especialmente a medida que aumenta el tamaño de la matriz. Esto se debe a que , tal y como analizamos en anteriores apartados el método recursivo tiene una complejidad factorial, lo que lo hace impracticable para matrices de tamaño moderado, mientras que el método de eliminación de Gauss tiene una complejidad cúbica, lo que lo hace mucho más manejable. Adicionalmente, el método más rápido salvo casos muy excepcionales es el de `numpy.linalg.det`, que está optimizado para cálculos numéricos y utiliza algoritmos avanzados para calcular determinantes de manera eficiente, superando incluso al método de eliminación de Gauss en términos de velocidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>2.a [1 pto] Prográmese en Python el método de descenso de gradiente para funciones de \"n\" variables. </b>\n",
    "- El gradiente de la función que se desea minimizar $\\nabla f$ (puede venir dada como otra función previamente implementada, `grad_f`, con entrada un vector, representando el punto donde se quiere calcular el gradiente, y salida otro vector, representando el gradiente de $f$ en dicho punto).\n",
    "- Un valor inicial $x_0 \\in \\mathbb{R}^n$ (almacenado en un vector de $n$ componentes).\n",
    "- El ratio de aprendizaje $\\gamma$ (que se asume constante para cada iteración).\n",
    "- Un parámetro de tolerancia `tol` (con el que finalizar el proceso cuando $\\|\\nabla f(x)\\|_2 < \\text{tol}$).\n",
    "- Un número máximo de iteraciones `maxit` (con el fin de evitar ejecuciones indefinidas en caso de divergencia o convergencia muy lenta).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(grad_f, initial_v, learnign_rate, tolerance, maxiterations=1000):\n",
    "    point = initial_v if isinstance(initial_v, np.ndarray) else np.array([initial_v], dtype=float)\n",
    "    is_converged = False\n",
    "\n",
    "    for _ in range(int(maxiterations)):\n",
    "        gradient = grad_f(point)\n",
    "        #print(f\"Gradiente del punto {point}: {gradient}\")\n",
    "        if np.linalg.norm(gradient) < tolerance:\n",
    "            print(f\"Converge en el punto {point} con una tolerancia de {tolerance} tras realizar {_} iteraciones.\")\n",
    "            is_converged = True\n",
    "            return point, is_converged, _ + 1\n",
    "        \n",
    "        point -= (learnign_rate * gradient)\n",
    "        \n",
    "    print(f\"No ha conseguido converger en {maxiterations} iteraciones.\")\n",
    "    return point, is_converged, maxiterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.b Sea la función $f : \\mathbb{R}^2 \\to \\mathbb{R}$ dada por: $f(x) = 3x^4 + 4x^3 -12x^2 + 7.$</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de gradiente de anterior función\n",
    "def one_vairable_grad_f(point):\n",
    "    return np.array([12*(point[0]**3) + 12*(point[0]**2) - 24*(point[0])], dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<b>2.b.I Aplica el método sobre $f(x)$ con $x_0=3$ y $\\gamma=0.001$, tol=1e-12, maxit=1e5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge en el punto [1.] con una tolerancia de 1e-12 tras realizar 831 iteraciones.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "result, is_converged, n_iterations = gradient_descent(one_vairable_grad_f, 3, 0.001, 1e-12 ,10000)\n",
    "data.append([\n",
    "    [3], \n",
    "    result, \n",
    "    \"Si\" if is_converged else \"No\", \n",
    "    0.001, \n",
    "    1e-12, \n",
    "    n_iterations\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**II** [0.5 puntos ]Aplica de nuevo el método sobre $f(x)$ con $x_0 = 3$, $\\gamma = 0.01$, `tol=1e-12`, `maxit=1e5`.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge en el punto [-2.] con una tolerancia de 1e-12 tras realizar 31 iteraciones.\n"
     ]
    }
   ],
   "source": [
    "result, is_converged, n_iterations= gradient_descent(one_vairable_grad_f, 3, 0.01, 1e-12 ,10000)\n",
    "data.append([\n",
    "    [3], \n",
    "    result, \n",
    "    \"Si\" if is_converged else \"No\", \n",
    "    0.01, \n",
    "    1e-12, \n",
    "    n_iterations\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**III** [0.5 puntos] Contrasta e interpreta los dos resultados obtenidos en los apartados anteriores y compáralos con los mínimos locales obtenidos analíticamente. </b> \n",
    "\n",
    "Los resultados obtenidos son los que muestra el siguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Punto Inicial</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Convergencia</th>\n",
       "      <th>Tasa de Aprendizaje</th>\n",
       "      <th>Tolerancia</th>\n",
       "      <th>Iteraciones hasta convergencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[1.0000000000000275]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[-1.9999999999999882]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Punto Inicial              Resultado Convergencia  Tasa de Aprendizaje  \\\n",
       "0           [3]   [1.0000000000000275]           Si                0.001   \n",
       "1           [3]  [-1.9999999999999882]           Si                0.010   \n",
       "\n",
       "     Tolerancia  Iteraciones hasta convergencia  \n",
       "0  1.000000e-12                             832  \n",
       "1  1.000000e-12                              32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_gradient = pd.DataFrame(\n",
    "    columns=[\"Punto Inicial\", \"Resultado\", \"Convergencia\", \"Tasa de Aprendizaje\", \"Tolerancia\", \"Iteraciones hasta convergencia\"],\n",
    "    data=data\n",
    ")\n",
    "\n",
    "display(df_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo $f$: $f(x) = 3x^4 + 4x^3 -12x^2 + 7.$, sabemos que su $f'(x) = 12x^3 + 12x^2 - 24x$, por lo que los puntos críticos son aquellos que cumplen $f'(x) = 0$, es decir, $12x^3 + 12x^2 - 24x = 0$. Resolviendo esta ecuación, encontramos los puntos críticos y sus correspondientes valores de $f$. Para ello, sacamos factor común $12x$:\n",
    "$$12x(x^2 + x - 2) = 0$$\n",
    "\n",
    "Resolviendo la ecuación cuadrática $x^2 + x - 2 = 0$ con la fórmula general, obtenemos dos soluciones:\n",
    "$$x_1 = 1, \\quad x_2 = -2$$\n",
    "\n",
    "Por lo tanto, los puntos críticos son $x_1 = 0$, $x_2 = 1$ y $x_3 = -2$. Evaluando la función en estos puntos, obtenemos:\n",
    "- $f(0) = 7$\n",
    "- $f(1) = 2$\n",
    "- $f(-2) = 3$\n",
    "\n",
    "Para saber si son máximos o mínimos locales, calculamos la segunda derivada $f''(x) = 36x^2 + 24x - 24$ y evaluamos en los puntos críticos:\n",
    "\n",
    "- $f''(0) = -24$ (máximo local)\n",
    "- $f''(1) = 36$ (mínimo local)\n",
    "- $f''(-2) = 72$ (mínimo local)\n",
    "\n",
    "En el caso de la ejecución del método de descenso de gradiente, los dos resultados que ha obtenido [1.0] en la primera ejecución y [-2.0] vemos que se corresponden con los puntos críticos que hemos obtenido análiticamente que son a su vez mínimos locales, por lo que podemos concluir que el método de descenso de gradiente ha convergido a los mínimos locales de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>¿Qué influencia puede llegar a tener la elección del ratio de aprendizaje $\\gamma$?</b>\n",
    "\n",
    "La diferencia entre ambos resultados se debe a la elección del ratio de aprendizaje:\n",
    "\n",
    "- Una tasa de aprendizaje más pequeña hace que el descenso sea más lento pero más preciso, permitiendo caer en el mínimo local más cercano al punto inicial.\n",
    "- Una tasa de aprendizaje más grande puede mover el punto inicial hacia otro valle antes de estabilizarse, llevándolo a otro mínimo local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**IV** [0.5 puntos] Aplica nuevamente el método sobre $f(x)$ con $x_0 = 3$, $\\gamma = 0.1$, `tol=1e-12`, `maxit=1e5`. Interpreta el resultado.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No ha conseguido converger en 10000 iteraciones.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maike\\AppData\\Local\\Temp\\ipykernel_28192\\111289885.py:3: RuntimeWarning: overflow encountered in scalar power\n",
      "  return np.array([12*(point[0]**3) + 12*(point[0]**2) - 24*(point[0])], dtype=float)\n",
      "C:\\Users\\maike\\AppData\\Local\\Temp\\ipykernel_28192\\111289885.py:3: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return np.array([12*(point[0]**3) + 12*(point[0]**2) - 24*(point[0])], dtype=float)\n"
     ]
    }
   ],
   "source": [
    "result, is_converged, n_iterations= gradient_descent(one_vairable_grad_f, 3, 0.1, 1e-12 ,10000)\n",
    "data.append([\n",
    "    [3], \n",
    "    result, \n",
    "    \"Si\" if is_converged else \"No\", \n",
    "    0.1, \n",
    "    1e-12, \n",
    "    n_iterations\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación del resultado:** Con esta tasa, el método da saltos muy grandes, lo que hace que los valores del gradiente crezcan exponencialmente, y por tanto, el método diverge. Esto indica que la tasa de aprendizaje es demasiado alta para esta función, lo que provoca que el algoritmo no converja a un mínimo local. Incluso nos llegan advertencia de `RuntimeWarning: overflow encountered in scalar power`, lo que indica que los valores se están volviendo demasiado grandes para ser representados correctamente en el tipo de dato utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**V** [0.5 puntos] Finalmente, aplica el método sobre $f(x)$ con $x_0 = 0$, $\\gamma = 0.001$, `tol=1e-12`, `maxit=1e5`.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge en el punto [0.] con una tolerancia de 1e-12 tras realizar 0 iteraciones.\n"
     ]
    }
   ],
   "source": [
    "result, is_converged, n_iterations= gradient_descent(one_vairable_grad_f, 0, 0.001, 1e-12 ,10000)\n",
    "\n",
    "data.append([\n",
    "    [0],\n",
    "    result,\n",
    "    \"Si\" if is_converged else \"No\",\n",
    "    0.001,\n",
    "    1e-12,\n",
    "    n_iterations\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Interpreta el resultado y compáralo con el estudio analítico de $f$. ¿Se trata de un resultado deseable? ¿Por qué? ¿A qué se debe este fenómeno?</b>\n",
    "\n",
    "el algoritmo **converge inmediatamente en la primera iteración**, detectando que ya cumple con la condición de tolerancia.\n",
    "\n",
    "Porque el gradiente de la función en $x=0$ es:\n",
    "\n",
    "$$\n",
    "f'(x) = 12x^3 + 12x^2 - 24x \\quad \\Rightarrow \\quad f'(0) = 0\n",
    "$$\n",
    "\n",
    "Esto implica que el algoritmo ya se encuentra en un punto crítico desde el inicio. Por lo tanto, **no necesita realizar ningún paso de actualización**: ya cumple la condición $ \\|\\nabla f(x)\\| < \\text{tol} $.\n",
    "\n",
    "**¿Es un resultado deseable?**\n",
    "\n",
    "En este caso concreto no, porque en $x=0$ no tenemos un mínimo local sino un máximo local tal y como ya vimos en el análisis previo.\n",
    "\n",
    "**¿A qué se debe este fenómeno?**\n",
    "\n",
    "Se debe a que el descenso por gradiente solo observa la magnitud del gradiente, no la naturaleza del punto crítico. Al iniciarse en \\( x = 0 \\), y tener gradiente nulo, asume erróneamente que ha encontrado un punto óptimo.\n",
    "\n",
    "**Conclusión:**\n",
    "\n",
    "Este resultado muestra una **limitación del método** cuando el punto inicial coincide con un punto crítico que **no es un mínimo local**. En estos casos, el análisis analítico previo (como el estudio del signo de la derivada o la convexidad) es clave para validar los resultados numéricos.\n",
    "\n",
    "### Resultados finales\n",
    "\n",
    "Se muestra una tabla resumen de los resultados obtenidos en el método de descenso de gradiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Punto Inicial</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Convergencia</th>\n",
       "      <th>Tasa de Aprendizaje</th>\n",
       "      <th>Tolerancia</th>\n",
       "      <th>Iteraciones hasta convergencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[1.0000000000000275]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[-1.9999999999999882]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>No</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Punto Inicial              Resultado Convergencia  Tasa de Aprendizaje  \\\n",
       "0           [3]   [1.0000000000000275]           Si                0.001   \n",
       "1           [3]  [-1.9999999999999882]           Si                0.010   \n",
       "2           [3]                  [nan]           No                0.100   \n",
       "3           [0]                  [0.0]           Si                0.001   \n",
       "\n",
       "     Tolerancia  Iteraciones hasta convergencia  \n",
       "0  1.000000e-12                             832  \n",
       "1  1.000000e-12                              32  \n",
       "2  1.000000e-12                           10000  \n",
       "3  1.000000e-12                               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_gradient = pd.DataFrame(\n",
    "    columns=[\"Punto Inicial\", \"Resultado\", \"Convergencia\", \"Tasa de Aprendizaje\", \"Tolerancia\", \"Iteraciones hasta convergencia\"],\n",
    "    data=data\n",
    ")\n",
    "\n",
    "display(df_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>c) Sea la función $g : \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ dada por</b>\n",
    "$$\n",
    "g(x, y) = x^2 + y^3 + 3xy + 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_variable_grad_f(point):\n",
    "    \"\"\"Calcula el gradiente de la función g(x, y) = x^2 + y^3 + 3xy + 1\"\"\"\n",
    "    x, y = point[0], point[1]\n",
    "    return np.array([\n",
    "        2*x + 3*y,\n",
    "        3*(y**2) + 3*x\n",
    "    ], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>**I [0.5 puntos]** Aplíquese el método sobre $g(x, y)$ con $x_0 = (-1, 1)$, $\\gamma = 0.01$, `tol=1e-12`, `maxit=1e5`.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge en el punto [-2.25  1.5 ] con una tolerancia de 1e-12 tras realizar 3139 iteraciones.\n"
     ]
    }
   ],
   "source": [
    "data2 = []\n",
    "\n",
    "result, is_converged, n_iterations = gradient_descent(two_variable_grad_f,np.array([-1, 1], dtype=float), 0.01, 1e-12 ,10000)\n",
    "\n",
    "data2.append([\n",
    "    np.array([-1, 1], dtype=float),\n",
    "    result,\n",
    "    \"Si\" if is_converged else \"No\",\n",
    "    0.01,\n",
    "    1e-12,\n",
    "    n_iterations\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>II [0.5 puntos] ¿Qué ocurre si ahora partimos de $x_0 = (0, 0)$? ¿Se obtiene un resultado deseable?</b> \n",
    "\n",
    "En este caso, hasta que no desarrollamos el punto 2.b.III no nos damos cuenta de que el punto \\(x_0 = (0, 0)\\) es un punto de silla de la función \\(g\\), por lo que el resultado que obtenemos no es deseable, ya que el algoritmo no converge a un mínimo local, sino que se queda en un punto de silla donde el gradiente es cero pero no es un mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converge en el punto [0. 0.] con una tolerancia de 1e-12 tras realizar 0 iteraciones.\n"
     ]
    }
   ],
   "source": [
    "result, is_converged, n_iterations = gradient_descent(two_variable_grad_f,np.array([0,0], dtype=float), 0.01, 1e-12 ,10000)\n",
    "\n",
    "data2.append([\n",
    "    np.array([-1, 1], dtype=float),\n",
    "    result,\n",
    "    \"Si\" if is_converged else \"No\",\n",
    "    0.01,\n",
    "    1e-12,\n",
    "    n_iterations\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>III [0.5 puntos] Realícese el estudio analítico de la función y utilícese para explicar y contrastar los resultados obtenidos en los dos apartados anteriores.</b>\n",
    "\n",
    "Los resultados obtenidos son los que muestra el siguiente código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso de la función $g(x, y) = x^2 + y^3 + 3xy + 1$, tenemos que:\n",
    "\n",
    "1. El gradiente es:\n",
    "$$\\nabla g(x, y) = \\left( \\frac{\\partial g}{\\partial x}, \\frac{\\partial g}{\\partial y} \\right) = (2x + 3y, 3y^2 + 3x)$$\n",
    "\n",
    "2. Los puntos críticos se obtienen resolviendo el sistema de ecuaciones:\n",
    "$$\n",
    "\\begin{cases}\n",
    "2x + 3y = 0 \\\\\n",
    "3y^2 + 3x = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "De este sistema, obtenemos dos puntos críticos:\n",
    "- \\( (0, 0) \\)\n",
    "- \\( (-2.25, 1.5) \\)\n",
    "\n",
    "3. El hessiano es:\n",
    "$$H_g(x, y) = \\begin{pmatrix} \\frac{\\partial^2 g}{\\partial x^2} & \\frac{\\partial^2 g}{\\partial x \\partial y} \\\\ \\frac{\\partial^2 g}{\\partial y \\partial x} & \\frac{\\partial^2 g}{\\partial y^2} \\end{pmatrix} = \\begin{pmatrix} 2 & 3 \\\\ 3 & 6y \\end{pmatrix}$$\n",
    "\n",
    "Si aplicamos el punto crítico \\( (0, 0) \\):\n",
    "$$H_g(0, 0) = \\begin{pmatrix} 2 & 3 \\\\ 3 & 0 \\end{pmatrix}$$\n",
    "\n",
    "Si aplicamos el criterio de Sylvester, vemos que el determinante es negativo:\n",
    "$$\\det(H_g(0, 0)) = 2 \\cdot 0 - 3 \\cdot 3 = -9 < 0$$\n",
    "\n",
    "Esto indica que \\( (0, 0) \\) es un punto de silla, no un mínimo local.\n",
    "\n",
    "Si aplicamos el punto crítico \\( (-2.25, 1.5) \\):\n",
    "$$H_g(-2.25, 1.5) = \\begin{pmatrix} 2 & 3 \\\\ 3 & 9 \\end{pmatrix}$$\n",
    "$$\\det(H_g(-2.25, 1.5)) = 2 \\cdot 9 - 3 \\cdot 3 = 18 - 9 = 9 > 0$$\n",
    "Esto indica que \\( (-2.25, 1.5) \\) es un mínimo local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Punto Inicial</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Convergencia</th>\n",
       "      <th>Tasa de Aprendizaje</th>\n",
       "      <th>Tolerancia</th>\n",
       "      <th>Iteraciones hasta convergencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1.0, 1.0]</td>\n",
       "      <td>[-2.2499999999989475, 1.4999999999996108]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>3140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>Si</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.000000e-12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Punto Inicial                                  Resultado Convergencia  \\\n",
       "0   [-1.0, 1.0]  [-2.2499999999989475, 1.4999999999996108]           Si   \n",
       "1   [-1.0, 1.0]                                 [0.0, 0.0]           Si   \n",
       "\n",
       "   Tasa de Aprendizaje    Tolerancia  Iteraciones hasta convergencia  \n",
       "0                 0.01  1.000000e-12                            3140  \n",
       "1                 0.01  1.000000e-12                               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result_multivariable = pd.DataFrame(\n",
    "    columns=[\"Punto Inicial\", \"Resultado\", \"Convergencia\", \"Tasa de Aprendizaje\", \"Tolerancia\", \"Iteraciones hasta convergencia\"],\n",
    "    data=data2\n",
    ")\n",
    "\n",
    "display(df_result_multivariable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que podemos apreciar es que el algoritmo de descenso de gradiente ha convergido al punto crítico \\( (-2.25, 1.5) \\), que es un mínimo local, lo cual es un resultado deseable.\n",
    "Sin embargo cuando usamos como punto inicial \\(x_0 = (0, 0)\\), el algoritmo no converge a un mínimo local, sino que se queda en un punto de silla donde el gradiente es cero pero no es un mínimo. Lo cual, como hemos visto, es un resultado no deseable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nombre Para Mostrar",
   "language": "python",
   "name": "nombre_del_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
