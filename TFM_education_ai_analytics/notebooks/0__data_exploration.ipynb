{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Análisis Exploratorio de Datos (EDA) - OULAD Dataset\n",
                "\n",
                "Este notebook tiene como objetivo comprender la estructura y características del dataset OULAD antes de proceder con modelados complejos.\n",
                "\n",
                "## Objetivos\n",
                "1. **Visualizar y entender la información**: ¿Cómo es el dataset?   \n",
                "2. **Distribución de Clases**: ¿Está desbalanceado el dataset (Pass vs Fail vs Withdrawn)?\n",
                "3. **Análisis Temporal**: ¿Cómo evoluciona la interacción de los estudiantes a lo largo de las semanas?\n",
                "4. **Correlaciones Iniciales**: ¿Existe relación visible entre el número de clics y el resultado final?\n",
                "\n",
                "\n",
                "# 1. Visualización de la información"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = [10, 6]\n",
                "\n",
                "DATA_DIR = Path(\"../data/interim\")\n",
                "\n",
                "df_students = pd.read_csv(DATA_DIR / \"students_merged.csv\")\n",
                "df_assessments = pd.read_csv(DATA_DIR / \"assessments_merged.csv\")\n",
                "df_interactions = pd.read_csv(DATA_DIR / \"interactions_merged.csv\")\n",
                "\n",
                "print(\"Datos cargados correctamente:\")\n",
                "print(f\"Estudiantes: {df_students.shape}\")\n",
                "print(f\"Evaluaciones: {df_assessments.shape}\")\n",
                "print(f\"Interacciones: {df_interactions.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:** Podemos ver que tenemos un dataset relativamente grande con el que podemos entrenar adecuadamente nuestros modelos de inteligencia artificial y que puedan generalizar bien."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.1. Significado de los datos\n",
                "\n",
                "A continuación se describe el contenido de las tablas generadas tras el preprocesamiento inicial del dataset OULAD.\n",
                "\n",
                "### Tabla 1: Estudiantes (`students_processed.csv`)\n",
                "Esta es la tabla maestra que contiene la información estática y demográfica de cada estudiante matriculado.\n",
                "\n",
                "| Campo | Descripción |\n",
                "| :--- | :--- |\n",
                "| `code_module` | Identificador del curso (ej. AAA, BBB). |\n",
                "| `code_presentation` | Semestre en el que se imparte (ej. 2013J, 2014B). |\n",
                "| `id_student` | ID único anonimizado del estudiante. |\n",
                "| `gender` | Género del estudiante (M/F). |\n",
                "| `region` | Región geográfica de residencia en UK. |\n",
                "| `highest_education` | Nivel educativo previo (ej. A Level, HE Qualification). |\n",
                "| `imd_band` | Índice de privación múltiple (nivel socioeconómico de la zona, % más bajo = más pobreza). |\n",
                "| `age_band` | Rango de edad (0-35, 35-55, 55<=). |\n",
                "| `num_of_prev_attempts` | Número de veces que ha intentado este módulo antes. |\n",
                "| `studied_credits` | Créditos totales que el estudiante está cursando actualmente. |\n",
                "| `disability` | Si tiene discapacidad declarada (Y/N). |\n",
                "| `final_result` | **Variable Objetivo**: Pass, Distinction, Fail, Withdrawn. |\n",
                "| `date_registration` | Día relativo al inicio del curso en que se matriculó. |\n",
                "| `date_unregistration` | Día relativo en que se dio de baja (si aplica). |\n",
                "\n",
                "---\n",
                "\n",
                "### Tabla 2: Evaluaciones (`assessments_processed.csv`)\n",
                "Contiene los resultados de todos los exámenes y tareas puntuables.\n",
                "\n",
                "| Campo | Descripción |\n",
                "| :--- | :--- |\n",
                "| `id_assessment` | ID de la prueba específica. |\n",
                "| `id_student` | ID del estudiante. |\n",
                "| `date_submitted` | Día relativo al inicio del curso en que el alumno entregó la tarea. |\n",
                "| `is_banked` | Si la nota ha sido convalidada de una presentación anterior. |\n",
                "| `score` | Nota obtenida (0-100). |\n",
                "| `assessment_type` | Tipo de examen: TMA (Tutor Marked), CMA (Computer Marked), Exam. |\n",
                "| `date` | Fecha límite de entrega oficial (Deadline). |\n",
                "| `weight` | Peso de esta evaluación en la nota final del curso. |\n",
                "\n",
                "---\n",
                "\n",
                "### Tabla 3: Interacciones (`interactions_processed.csv`)\n",
                "Es el log de actividad diario en el VLE (Virtual Learning Environment). Es la tabla más voluminosa.\n",
                "\n",
                "| Campo | Descripción |\n",
                "| :--- | :--- |\n",
                "| `code_module` | Módulo visitado. |\n",
                "| `id_student` | ID del estudiante. |\n",
                "| `id_site` | ID del material específico visitado. |\n",
                "| `date` | Día relativo al inicio del curso (puede ser negativo si accedió antes de que empezará). |\n",
                "| `sum_click` | Número de clics realizados en ese material ese día. |\n",
                "| `activity_type` | Tipo de recurso: `forumng` (foro), `oucontent` (contenido HTML), `resource` (PDF/Web), `quiz`, etc. |\n",
                "| `week_from / week_to` | Semanas planificadas para ese material (muchos nulos). |\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 Primera toma de contacto con los datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hacemos un display de las primeras filas para familiarizarnos con las columnas\n",
                "print(\"--- DATOS DE ESTUDIANTES (Demográficos y Resultado) ---\")\n",
                "display(df_students.head(3))\n",
                "\n",
                "print(\"\\n--- DATOS DE EVALUACIONES (Notas) ---\")\n",
                "display(df_assessments.head(3))\n",
                "\n",
                "print(\"\\n--- DATOS DE INTERACCIONES (Clics en recursos) ---\")\n",
                "display(df_interactions.head(3))\n",
                "\n",
                "# Verificamos si hay nulos\n",
                "print(\"\\n--- VALORES NULOS POR DATASET ---\")\n",
                "print(\"Estudiantes:\", df_students.isnull().sum().sum())\n",
                "print(\"Evaluaciones:\", df_assessments.isnull().sum().sum())\n",
                "print(\"Interacciones:\", df_interactions.isnull().sum().sum())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Análisis Detallado de Nulos\n",
                "Dado que hemos detectado la presencia de valores faltantes, vamos a identificar el porcentaje que representan. En el dataset OULAD, muchos nulos tienen un **significado estructural** y no son errores de carga."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANÁLISIS Y JUSTIFICACIÓN DE VALORES NULOS ---\n",
                "print(\"Recuento de valores nulos por tabla:\")\n",
                "for name, df in [(\"Estudiantes\", df_students), (\"Evaluaciones\", df_assessments), (\"Interacciones\", df_interactions)]:\n",
                "    nulls = df.isnull().sum()\n",
                "    print(f\"\\nTabbla {name}:\")\n",
                "    print(nulls[nulls > 0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Justificación de Decisiones de Preprocesamiento (Basado en EDA)\n",
                "\n",
                "A continuación, se presentan las pruebas estadísticas que justifican las reglas de limpieza aplicadas en el script `dataset.py`. El objetivo es maximizar la retención de datos útiles sin introducir ruido o sesgos en el modelo:\n",
                "\n",
                "1.  **Preservación de Estudiantes sin Registro:** Se analiza si los estudiantes con `date_registration` nulo poseen actividad relevante que justifique su imputación en lugar de su eliminación.\n",
                "2.  **Tratamiento de Nivel Socioeconómico (`imd_band`):** Se evalúa el impacto de la categoría `'Unknown'` para mantener la representatividad de la muestra.\n",
                "3.  **Saneamiento de Evaluaciones:** Validación del impacto porcentual de la eliminación de registros sin calificación (`score`).\n",
                "4.  **Validación de Imputación Temporal:** Análisis de la mediana de registro por cohorte para asegurar que la imputación no viola la estructura temporal del curso."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. JUSTIFICACIÓN: ¿Por qué no borrar los 45 estudiantes sin date_registration? ---\n",
                "# Vamos a ver si estos estudiantes tienen actividad (interacciones y notas)\n",
                "ids_sin_registro = df_students[df_students['date_registration'].isnull()]['id_student']\n",
                "actividad_vle = df_interactions[df_interactions['id_student'].isin(ids_sin_registro)].shape[0]\n",
                "actividad_notas = df_assessments[df_assessments['id_student'].isin(ids_sin_registro)].shape[0]\n",
                "\n",
                "print(f\"Alumnos sin fecha de registro: {len(ids_sin_registro)}\")\n",
                "print(f\"-> Total de clics que perderíamos si los borramos: {actividad_vle}\")\n",
                "print(f\"-> Total de notas que perderíamos si los borramos: {actividad_notas}\")\n",
                "# CONCLUSIÓN: Imputamos la mediana para no perder miles de registros de comportamiento.\n",
                "\n",
                "# --- 2. JUSTIFICACIÓN: ¿Por qué imputar 'Unknown' en imd_band? ---\n",
                "print(\"\\nDistribución de imd_band (incluyendo nulos):\")\n",
                "print(df_students['imd_band'].value_counts(dropna=False, normalize=True) * 100)\n",
                "# CONCLUSIÓN: El 3.4% de nulos es significativo. Convertirlo en 'Unknown' evita sesgos\n",
                "\n",
                "# --- 3. JUSTIFICACIÓN: ¿Por qué borrar los 173 registros sin score? ---\n",
                "print(f\"\\nPorcentaje de notas faltantes: {(173 / len(df_assessments)) * 100:.4f}%\")\n",
                "\n",
                "# --- 4. DATA LEAKAGE PREVENTION CHECK ---\n",
                "print(\"\\nMediana de date_registration por cohorte (justifica imputación agrupada):\")\n",
                "print(df_students.groupby('code_presentation')['date_registration'].median())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Síntesis de Resultados y Decisiones Finales\n",
                "\n",
                "Tras el análisis detallado de los valores faltantes, se confirman las siguientes acciones ejecutadas en el pipeline de ingeniería de datos:\n",
                "\n",
                "*   **Retención de Estudiantes \"Huéspedes\":** Los estudiantes sin fecha de registro presentan una actividad significativa en el VLE y evaluaciones. Su eliminación habría supuesto una pérdida de datos conductuales valiosos. La imputación mediante la mediana por cohorte preserva estos registros sin distorsionar la distribución temporal.\n",
                "*   **Tratamiento de Datos Socioeconómicos:** El volumen de nulos en `imd_band` (~3.4%) es representativo. La categorización como `'Unknown'` permite mantener a estos individuos en el estudio, evitando un sesgo hacia alumnos de los que sí se dispone de información privada compleja.\n",
                "*   **Saneamiento de la Variable Objetivo:** La eliminación de los registros de evaluación sin `score` es marginal (0.01%) y necesaria para asegurar que el modelo se entrene exclusivamente con etiquetas de rendimiento verificadas.\n",
                "*   **Alineación Temporal Coherente:** Se confirma que la fecha de registro varía según la presentación (`code_presentation`), lo que valida que la imputación debe ser siempre **condicional al curso** y nunca global.\n",
                "\n",
                "Estas decisiones garantizan un dataset final robusto, donde el **99.9% de los estudiantes originales** y sus interacciones son aprovechados para el entrenamiento de los modelos predictivos.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Distribución de la Variable Objetivo (final_result)\n",
                "Es crucial saber si tenemos clases desbalanceadas, ya que esto afectará a las métricas del modelo futuro."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Traducción de etiquetas para la gráfica\n",
                "translation_map = {\n",
                "    'Pass': 'Aprobado',\n",
                "    'Distinction': 'Sobresaliente',\n",
                "    'Fail': 'Suspenso',\n",
                "    'Withdrawn': 'Abandono'\n",
                "}\n",
                "\n",
                "df_students['Resultado'] = df_students['final_result'].map(translation_map)\n",
                "\n",
                "plt.figure(figsize=(9, 6))\n",
                "ax = sns.countplot(\n",
                "    data=df_students, \n",
                "    x='Resultado', \n",
                "    palette='viridis', \n",
                "    order=['Aprobado', 'Sobresaliente', 'Suspenso', 'Abandono']\n",
                ")\n",
                "\n",
                "# Añadir etiquetas de valor encima de las barras\n",
                "for i in ax.containers:\n",
                "    ax.bar_label(i)\n",
                "\n",
                "plt.title(\"Distribución de Estudiantes por Resultado Final\", fontsize=14)\n",
                "plt.xlabel(\"Resultado Académico\", fontsize=12)\n",
                "plt.ylabel(\"Cantidad de Estudiantes\", fontsize=12)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:** El análisis de la distribución de clases revela un escenario complejo que justifica la necesidad de modelos avanzados. Si planteamos el problema de forma binaria como \"Persistencia\" (Aprobado + Sobresaliente ≈ 15.3k) frente a \"Riesgo\" (Suspenso + Abandono ≈ 17.2k), el dataset se encuentra razonablemente balanceado, lo cual es ideal para el entrenamiento. Sin embargo, al desglosar el riesgo, observamos que el Abandono (10.1k) es significativamente más frecuente que el Suspenso académico (7k). Esta disparidad refuerza la hipótesis de que la deserción es el problema principal a atajar y sugiere que un modelo multiclasificador será más efectivo para distinguir entre quien se va prematuramente y quien falla por rendimiento."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Estudio de interacciones de los estudiantes\n",
                "\n",
                "El dataset OULAD posee una naturaleza intrínsecamente secuencial que lo distingue de los conjuntos de datos estáticos tradicionales. Tanto las interacciones diarias en el VLE (date, sum_click) como las evaluaciones (date_submitted, score) se distribuyen a lo largo del tiempo, conformando la \"huella digital\" del aprendizaje de cada estudiante semana a semana. Esta estructura temporal es el fundamento ideal para la aplicación de arquitecturas basadas en Transformers. Al igual que estos modelos procesan palabras en una oración para entender el contexto, aquí procesaremos la secuencia de comportamientos semanales del alumno para predecir su trayectoria futura, permitiendo al sistema capturar dependencias a largo plazo (e.g., una baja actividad en la semana 2 que repercute en el examen de la semana 10) que modelos clásicos pasarían por alto.\n",
                "\n",
                "### 2.1 Clics promedios diarios\n",
                "\n",
                "Si miramos a un solo estudiante, su gráfica podría ser engañosa: quizás ese alumno solo estudia los domingos, o quizás se puso enfermo una semana. Al usar el promedio de todos, lo que emerge es el ritmo real del curso. Verás que todos los alumnos (en promedio) suben su actividad justo antes de una entrega. El promedio nos permite ver los hitos del calendario académico que afectan a la masa."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Calculamos el promedio de clics diarios de todos los estudiantes\n",
                "daily_activity = df_interactions.groupby('date')['sum_click'].mean().reset_index()\n",
                "\n",
                "# 2. Modificamos el filtro para incluir la actividad PREVIA (desde el día -25)\n",
                "# Mantenemos el límite de 240 para no desvirtuar el final\n",
                "daily_activity_filtered = daily_activity[(daily_activity['date'] >= -25) & (daily_activity['date'] <= 240)]\n",
                "\n",
                "plt.figure(figsize=(15, 5))\n",
                "\n",
                "# 3. Dibujamos la línea de actividad\n",
                "plt.plot(daily_activity_filtered['date'], daily_activity_filtered['sum_click'], color='#e74c3c', linewidth=1)\n",
                "\n",
                "# 4. Añadimos una línea vertical en el Día 0 para marcar el inicio oficial\n",
                "plt.axvline(x=0, color='black', linestyle='--', alpha=0.8, label='Inicio oficial del curso (Día 0)')\n",
                "\n",
                "plt.title('Promedio de Interacciones Diarias (Incluyendo Periodo Pre-Lectivo)', fontsize=14)\n",
                "plt.xlabel('Día del curso (Días negativos = actividad antes del inicio)', fontsize=12)\n",
                "plt.ylabel('Promedio de Clics', fontsize=12)\n",
                "plt.legend()\n",
                "plt.grid(True, linestyle='--', alpha=0.6)\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:**  Se aprecia un alto nivel de ruido y volatilidad en la actividad diaria (efecto sierra), lo que dificultaría el entrenamiento de un modelo de IA. También se confirma actividad relevante en los días previos al inicio oficial (Día < 0). Esta inestabilidad justifica la agregación semanal, necesaria para limpiar el ruido y capturar patrones de comportamiento más robustos y útiles para el modelo."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 clics promedio semanales"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Preparamos los datos\n",
                "# Actividad Diaria\n",
                "daily_avg = df_interactions.groupby('date')['sum_click'].mean().reset_index()\n",
                "\n",
                "# Actividad Semanal (Agrupamos primero por estudiante/semana y luego promediamos)\n",
                "df_interactions['week'] = df_interactions['date'] // 7\n",
                "weekly_avg = df_interactions.groupby(['id_student', 'week'])['sum_click'].sum().reset_index()\n",
                "weekly_trend = weekly_avg.groupby('week')['sum_click'].mean().reset_index()\n",
                "\n",
                "# 2. Configuración de la comparativa\n",
                "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=False)\n",
                "\n",
                "# Gráfica Superior: Ruido Diario\n",
                "ax1.plot(daily_avg['date'], daily_avg['sum_click'], color='#e74c3c', linewidth=1, alpha=0.8)\n",
                "ax1.axvline(x=0, color='black', linestyle='--')\n",
                "ax1.set_title('ANÁLISIS DIARIO: Ruido de alta frecuencia (difícil de modelar)', fontsize=14)\n",
                "ax1.set_ylabel('Promedio Clics/Día')\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# Gráfica Inferior: Señal Semanal\n",
                "# Multiplicamos X por 7 para mantener la misma escala temporal que los días\n",
                "ax2.plot(weekly_trend['week'] * 7, weekly_trend['sum_click'], color='#3498db', linewidth=3, marker='o')\n",
                "ax2.axvline(x=0, color='black', linestyle='--')\n",
                "ax2.set_title('ANÁLISIS SEMANAL: Señal limpia y patrones identificables', fontsize=14)\n",
                "ax2.set_ylabel('Promedio Clics/Semana')\n",
                "ax2.set_xlabel('Días del curso')\n",
                "ax2.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:** El contraste visual es definitivo: mientras que la serie diaria está saturada de variaciones bruscas (ruido) que no aportan valor predictivo, la agregación semanal filtra esas fluctuaciones y revela la estructura real del curso.\n",
                "\n",
                "Al usar semanas, transformamos datos caóticos en una serie temporal limpia donde destacan los hitos académicos. Esta es la base que permitirá al modelo (Transformer/RNN) aprender de forma eficiente, evitando que se pierda en detalles irrelevantes del día a día y centrando su capacidad en la evolución del compromiso del estudiante."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## --- ANÁLISIS POR RENDIMIENTO: ¿Quién deja de estudiar en las zonas críticas? ---\n",
                "\n",
                "# 1. Enriquecer Interacciones con el Resultado Final\n",
                "student_weekly = df_interactions.groupby(['id_student', 'week'])['sum_click'].sum().reset_index()\n",
                "student_weekly = student_weekly.merge(df_students[['id_student', 'final_result']], on='id_student', how='inner')\n",
                "\n",
                "# Traducimos etiquetas\n",
                "traduccion = {'Pass': 'Aprobado', 'Distinction': 'Sobresaliente', 'Fail': 'Suspenso', 'Withdrawn': 'Abandono'}\n",
                "student_weekly['Resultado'] = student_weekly['final_result'].map(traduccion)\n",
                "\n",
                "# 2. Calcular Promedios por Grupo\n",
                "trends_by_result = student_weekly.groupby(['Resultado', 'week'])['sum_click'].mean().reset_index()\n",
                "\n",
                "# <<< RECALCULO DE SEMANAS CRÍTICAS (Para autonomía de celda) >>>\n",
                "df_assessments['week_deadline'] = df_assessments['date'] // 7\n",
                "deadline_counts = df_assessments['week_deadline'].value_counts()\n",
                "semanas_criticas_local = deadline_counts[deadline_counts > deadline_counts.mean()].index\n",
                "\n",
                "# 3. Visualización\n",
                "plt.figure(figsize=(15, 7))\n",
                "\n",
                "# Líneas de Tendencia\n",
                "custom_colors = {'Abandono': '#e74c3c', 'Suspenso': '#f39c12', 'Aprobado': '#3498db', 'Sobresaliente': '#2ecc71'}\n",
                "sns.lineplot(data=trends_by_result, x='week', y='sum_click', hue='Resultado', palette=custom_colors, linewidth=2.5, marker='o')\n",
                "\n",
                "# Zonas de Alta Carga\n",
                "for semana in semanas_criticas_local: # Usamos la variable local\n",
                "    plt.axvspan(semana - 0.5, semana + 0.5, color='gray', alpha=0.15)\n",
                "\n",
                "# Estilos\n",
                "plt.title('Huella Digital del Éxito: Actividad Semanal según Resultado Final', fontsize=16)\n",
                "plt.ylabel('Promedio de Clics por Estudiante')\n",
                "plt.xlabel('Semana del Curso')\n",
                "plt.grid(True, linestyle='--', alpha=0.5)\n",
                "plt.legend(title='Resultado Final', loc='upper right')\n",
                "plt.xlim(-2, 39)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:** Se aprecia una distorsión de los datos en las últimas semanas del grupo de Abandono, con un pico de actividad atípico. Esto se debe a la baja representatividad estadística (pocos alumnos residuales), donde acciones individuales —como entrar a descargar materiales antes de irse o consultar notas finales en el \"cierre de actas\"— disparan el promedio. Dada esta volatilidad por falta de volumen, es recomendable truncar o normalizar los datos finales antes de alimentar el modelo de IA para evitar sesgos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANÁLISIS CUALITATIVO: ¿En qué invierten su tiempo? (Clics por Tipo de Recurso) ---\n",
                "\n",
                "# 1. Preparar datos\n",
                "# Hacemos merge para tener interactividad + resultado\n",
                "merged = df_interactions.merge(df_students[['id_student', 'final_result']], on='id_student', how='inner')\n",
                "\n",
                "# Traducimos resultados\n",
                "traduccion = {'Pass': 'Aprobado', 'Distinction': 'Sobresaliente', 'Fail': 'Suspenso', 'Withdrawn': 'Abandono'}\n",
                "merged['Resultado'] = merged['final_result'].map(traduccion)\n",
                "\n",
                "# 2. Calcular Distribución de Clics\n",
                "# Agrupamos por Resultado y Tipo de Actividad\n",
                "activity_dist = merged.groupby(['Resultado', 'activity_type'])['sum_click'].sum().reset_index()\n",
                "\n",
                "# Calculamos el total de clics por grupo para sacar porcentajes\n",
                "total_clicks_by_result = merged.groupby('Resultado')['sum_click'].sum().reset_index()\n",
                "activity_dist = activity_dist.merge(total_clicks_by_result, on='Resultado', suffixes=('', '_total'))\n",
                "activity_dist['percentage'] = (activity_dist['sum_click'] / activity_dist['sum_click_total']) * 100\n",
                "\n",
                "# 3. Pivotar para Heatmap\n",
                "heatmap_data = activity_dist.pivot(index='activity_type', columns='Resultado', values='percentage')\n",
                "# Ordenamos las actividades por popularidad global para que el gráfico sea legible\n",
                "top_activities = merged.groupby('activity_type')['sum_click'].sum().sort_values(ascending=False).index\n",
                "heatmap_data = heatmap_data.reindex(top_activities)\n",
                "# Reordenamos columnas lógicamente\n",
                "heatmap_data = heatmap_data[['Abandono', 'Suspenso', 'Aprobado', 'Sobresaliente']]\n",
                "\n",
                "# 4. Visualización\n",
                "plt.figure(figsize=(10, 12))\n",
                "sns.heatmap(heatmap_data, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", linewidths=.5, cbar_kws={'label': '% del Total de Clics del Grupo'})\n",
                "plt.title('Perfil de Navegación: ¿Qué consumen los diferentes estudiantes?', fontsize=14)\n",
                "plt.ylabel('Tipo de Recurso')\n",
                "plt.xlabel('Resultado Final')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Hallazgos del Análisis Temporal\n",
                "\n",
                "*   **Brecha de Actividad**: Se observa una clara separación entre estudiantes excelentes y en riesgo durante el ecuador del curso (Semanas 15-25). Los alumnos de alto rendimiento son proactivos, mientras que los de bajo rendimiento son reactivos a las entregas.\n",
                "*   **Limitación de Hitos Globales**: Los picos de actividad no siempre coinciden con los *deadlines* globales de la universidad, lo que sugiere que para la IA será vital capturar patrones específicos de cada módulo.\n",
                "*   **Señal vs Ruido**: La agregación semanal es fundamental para eliminar la volatilidad diaria y permitir que el modelo capture la trayectoria real del estudiante."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANÁLSIS DE PATRONES DE ABANDONO VS RENDIMIENTO ---\n",
                "# Objetivo: Comprender la dinámica temporal y el comportamiento diferencial entre\n",
                "# estudiantes que tienen éxito y aquellos que abandonan. Esta información será\n",
                "# clave para diseñar el sistema de alerta temprana basado en Transformers.\n",
                "# --- TRIPLE DESGLOSE: Top 3 Cursos por Resultado Final ---\n",
                "# 1. Identificar Top 3 Cursos Masivos\n",
                "top_3_courses = df_students.groupby(['code_module', 'code_presentation']).size().sort_values(ascending=False).head(3)\n",
                "# 2. Configuración Visual\n",
                "fig, axes = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
                "result_colors = {'Aprobado': '#3498db', 'Sobresaliente': '#2ecc71', 'Suspenso': '#f39c12', 'Abandono': '#e74c3c'}\n",
                "traduccion = {'Pass': 'Aprobado', 'Distinction': 'Sobresaliente', 'Fail': 'Suspenso', 'Withdrawn': 'Abandono'}\n",
                "# 3. Bucle para generar los 3 gráficos\n",
                "for i, ((curso, semestre), _) in enumerate(top_3_courses.items()):\n",
                "    ax = axes[i]\n",
                "    \n",
                "    # A. Filtrar Datos Específicos\n",
                "    # Estudiantes de este curso concreto con su nota final\n",
                "    sub_students = df_students[(df_students['code_module'] == curso) & (df_students['code_presentation'] == semestre)][['id_student', 'final_result']]\n",
                "    # Interacciones de este curso\n",
                "    sub_inter = df_interactions[(df_interactions['code_module'] == curso) & (df_interactions['code_presentation'] == semestre)]\n",
                "    # Deadlines de este curso\n",
                "    sub_assess = df_assessments[(df_assessments['code_module'] == curso) & (df_assessments['code_presentation'] == semestre)]\n",
                "    \n",
                "    # B. Merge para tener 'final_result' en las interacciones\n",
                "    merged_data = sub_inter.merge(sub_students, on='id_student', how='inner')\n",
                "    merged_data['Resultado'] = merged_data['final_result'].map(traduccion)\n",
                "    merged_data['week'] = merged_data['date'] // 7\n",
                "    \n",
                "    # C. Agrupar (Media de clics por resultado y semana)\n",
                "    # Primero sumamos por alumno/semana, luego promediamos por grupo\n",
                "    student_level = merged_data.groupby(['id_student', 'Resultado', 'week'])['sum_click'].sum().reset_index()\n",
                "    trend_data = student_level.groupby(['Resultado', 'week'])['sum_click'].mean().reset_index()\n",
                "    \n",
                "    # D. Pintar Líneas por Resultado\n",
                "    sns.lineplot(data=trend_data, x='week', y='sum_click', hue='Resultado', palette=result_colors, ax=ax, linewidth=2, marker='o')\n",
                "    \n",
                "    # E. Pintar Deadlines (Fondo Rojo)\n",
                "    deadlines = (sub_assess['date'] // 7).unique()\n",
                "    for d in deadlines:\n",
                "        ax.axvline(x=d, color='gray', linestyle=':', alpha=0.5)\n",
                "        ax.axvspan(d - 0.5, d + 0.5, color='gray', alpha=0.1)\n",
                "        \n",
                "    # F. Cosmética\n",
                "    ax.set_title(f'Dinámicas en {curso} ({semestre})', fontsize=12, fontweight='bold')\n",
                "    ax.set_ylabel('Clics/Alumno')\n",
                "    ax.legend(loc='upper right', fontsize='small', ncol=2)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "plt.xlabel('Semana del Curso')\n",
                "plt.xlim(-2, 39)\n",
                "plt.suptitle('Análisis de Comportamiento por Éxito en los Cursos Principales', fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Usamos la columna 'date' (fecha deadline oficial) si existe, o 'date_submitted'\n",
                "if 'date' in train_assessments.columns:\n",
                "    target_date = 'date'\n",
                "else:\n",
                "    target_date = 'date_submitted' # Fallback si no está la oficial\n",
                "\n",
                "# Gráfico de violín para ver la distribución temporal\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.violinplot(x='assessment_type', y=target_date, data=train_assessments, palette='viridis')\n",
                "plt.title(\"Distribución Temporal de Tipos de Evaluación\")\n",
                "plt.ylabel(\"Día del Curso (Deadline)\")\n",
                "plt.xlabel(\"Tipo de Evaluación\")\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "\n",
                "# Dibujar líneas de referencia (Semana 0 y Semana 35)\n",
                "plt.axhline(0, color='r', linestyle='--', alpha=0.5, label='Inicio Curso')\n",
                "plt.axhline(240, color='k', linestyle='--', alpha=0.5, label='Fin Curso (~Day 240)')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Estadísticas descriptivas\n",
                "print(\"Resumen de Fechas (Días) por Tipo:\")\n",
                "print(train_assessments.groupby('assessment_type')[target_date].describe()[['min', 'mean', 'max', 'count']])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Correlación: Clics Totales vs Nota Media\n",
                "¿Estudiar más (más clics) garantiza mejor nota?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculamos clics totales por estudiante\n",
                "total_clicks = df_interactions.groupby('id_student')['sum_click'].sum().reset_index()\n",
                "total_clicks.rename(columns={'sum_click': 'total_clicks'}, inplace=True)\n",
                "\n",
                "# Calculamos nota media por estudiante (en evaluaciones puntuables)\n",
                "avg_score = df_assessments.groupby('id_student')['score'].mean().reset_index()\n",
                "avg_score.rename(columns={'score': 'mean_score'}, inplace=True)\n",
                "\n",
                "# Unimos\n",
                "analysis_df = pd.merge(total_clicks, avg_score, on='id_student')\n",
                "analysis_df = pd.merge(analysis_df, df_students[['id_student', 'final_result']], on='id_student')\n",
                "\n",
                "# Traducción para visualización\n",
                "analysis_df['Resultado'] = analysis_df['final_result'].map(translation_map)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=analysis_df, x='total_clicks', y='mean_score', hue='Resultado', alpha=0.6, palette='viridis')\n",
                "plt.title(\"Relación entre Clics Totales y Nota Media\")\n",
                "plt.xscale('log') # Escala logarítmica porque suele haber outliers con muchísimos clics\n",
                "plt.xlabel(\"Clics Totales (Escala Logarítmica)\")\n",
                "plt.ylabel(\"Nota Media\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- ANÁLISIS DEMOGRÁFICO: Estilo Barras Agrupadas por Quintil ---\n",
                "\n",
                "# 1. Preparar Datos y Agrupar en 5 Quintiles\n",
                "demo_df = df_students.dropna(subset=['imd_band']).copy()\n",
                "\n",
                "im_mapping = {\n",
                "    '0-10%': '0-20% (Muy Baja)', '10-20': '0-20% (Muy Baja)',\n",
                "    '20-30%': '20-40% (Baja)',   '30-40%': '20-40% (Baja)',\n",
                "    '40-50%': '40-60% (Media)',  '50-60%': '40-60% (Media)',\n",
                "    '60-70%': '60-80% (Alta)',   '70-80%': '60-80% (Alta)',\n",
                "    '80-90%': '80-100% (Muy Alta)', '90-100%': '80-100% (Muy Alta)'\n",
                "}\n",
                "demo_df['Quintil_Riqueza'] = demo_df['imd_band'].map(im_mapping)\n",
                "orden_quintiles = ['0-20% (Muy Baja)', '20-40% (Baja)', '40-60% (Media)', '60-80% (Alta)', '80-100% (Muy Alta)']\n",
                "\n",
                "# 2. Calcular Porcentajes (Formato Largo para Seaborn)\n",
                "# Contamos alumnos por Quintil y Resultado\n",
                "grouped = demo_df.groupby(['Quintil_Riqueza', 'final_result']).size().reset_index(name='count')\n",
                "\n",
                "# Calculamos el total por Quintil para sacar el %\n",
                "total_by_quintil = grouped.groupby('Quintil_Riqueza')['count'].transform('sum')\n",
                "grouped['percentage'] = (grouped['count'] / total_by_quintil) * 100\n",
                "\n",
                "# Traducimos para la leyenda\n",
                "traduccion = {'Pass': 'Aprobado', 'Distinction': 'Sobresaliente', 'Fail': 'Suspenso', 'Withdrawn': 'Abandono'}\n",
                "grouped['Resultado'] = grouped['final_result'].map(traduccion)\n",
                "\n",
                "# 3. Visualización (Barras Agrupadas)\n",
                "plt.figure(figsize=(14, 7))\n",
                "\n",
                "colores_custom = {'Abandono': '#e74c3c', 'Suspenso': '#f39c12', 'Aprobado': '#3498db', 'Sobresaliente': '#2ecc71'}\n",
                "\n",
                "sns.barplot(\n",
                "    data=grouped,\n",
                "    x='Quintil_Riqueza',\n",
                "    y='percentage',\n",
                "    hue='Resultado',\n",
                "    hue_order=['Abandono', 'Suspenso', 'Aprobado', 'Sobresaliente'],\n",
                "    palette=colores_custom,\n",
                "    order=orden_quintiles # Aseguramos el orden lógico de pobreza a riqueza\n",
                ")\n",
                "\n",
                "# Cosmética\n",
                "plt.title('Impacto Socioeconómico: Distribución de Resultados por Nivel de Riqueza', fontsize=16)\n",
                "plt.xlabel('Nivel de Riqueza de la Región (Quintiles)')\n",
                "plt.ylabel('% de Estudiantes del Grupo')\n",
                "plt.legend(title='Resultado Final', bbox_to_anchor=(1.01, 1), loc='upper left')\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- TRIPLETE FINAL (Versión Mejorada con Desglose Semanal por Éxito) ---\n",
                "\n",
                "# CONFIGURACIÓN GENERAL\n",
                "fig = plt.figure(figsize=(20, 18))\n",
                "gs = fig.add_gridspec(3, 2) \n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# GRÁFICA 1: SUPERVIVENCIA\n",
                "# ---------------------------------------------------------\n",
                "ax1 = fig.add_subplot(gs[0, :])\n",
                "withdrawals = df_students[df_students['date_unregistration'].notna()]['date_unregistration']\n",
                "sns.histplot(withdrawals, kde=True, element=\"step\", fill=False, cumulative=True, color='red', ax=ax1, lw=3)\n",
                "ax1.clear()\n",
                "sns.histplot(withdrawals, bins=50, color='#e74c3c', kde=True, ax=ax1)\n",
                "ax1.set_title('Cronología del Abandono: ¿Cuándo se rinden los estudiantes?', fontsize=16)\n",
                "ax1.set_ylabel('Número de Abandonos')\n",
                "ax1.axvline(0, color='black', linestyle='--')\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# GRÁFICA 2: CORRELACIÓN PRIMERA NOTA\n",
                "# ---------------------------------------------------------\n",
                "ax2 = fig.add_subplot(gs[1, 0]) \n",
                "first_scores = df_assessments.sort_values('date_submitted').groupby('id_student').first().reset_index()\n",
                "score_corr = first_scores.merge(df_students[['id_student', 'final_result']], on='id_student')\n",
                "traduccion_nota = {'Pass': 'Aprobado', 'Distinction': 'Sobresaliente', 'Fail': 'Suspenso', 'Withdrawn': 'Abandono'}\n",
                "score_corr['Resultado'] = score_corr['final_result'].map(traduccion_nota)\n",
                "sns.boxplot(x='Resultado', y='score', data=score_corr, order=['Abandono', 'Suspenso', 'Aprobado', 'Sobresaliente'], palette='viridis', ax=ax2)\n",
                "ax2.set_title('Impacto de la Primera Nota', fontsize=14)\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# GRÁFICA 3: HÁBITOS SEMANALES DESGLOSADOS\n",
                "# ---------------------------------------------------------\n",
                "ax3 = fig.add_subplot(gs[1, 1])\n",
                "\n",
                "# 1. Preparamos datos enriquecidos (Interacción + Resultado)\n",
                "# Usamos una muestra más grande para que el desglose sea fiable\n",
                "sample_int_enriched = df_interactions.sample(1500000, random_state=42).merge(\n",
                "    df_students[['id_student', 'final_result']], on='id_student', how='inner'\n",
                ")\n",
                "sample_int_enriched['dia_semana'] = sample_int_enriched['date'] % 7\n",
                "sample_int_enriched['Resultado'] = sample_int_enriched['final_result'].map(traduccion_nota)\n",
                "\n",
                "# 2. Agrupamos: Clics totales por (Día, Resultado)\n",
                "weekly_breakdown = sample_int_enriched.groupby(['dia_semana', 'Resultado'])['sum_click'].sum().reset_index()\n",
                "\n",
                "# 3. Normalizamos (Opcional, pero recomendado):\n",
                "# Como hay muchos más aprobados que suspensos, las barras azules serán gigantes siempre.\n",
                "# Para ver PATRONES horariros, calculamos el % de actividad diaria DENTRO de cada grupo.\n",
                "# (Ej: Del 100% de clics de los Sobresalientes, ¿cuánto cae en Domingo?)\n",
                "total_clicks_per_group = weekly_breakdown.groupby('Resultado')['sum_click'].transform('sum')\n",
                "weekly_breakdown['pct_click'] = (weekly_breakdown['sum_click'] / total_clicks_per_group) * 100\n",
                "\n",
                "# 4. Visualización con Barras Agrupadas (hue)\n",
                "# Orden de días para que quede bonito\n",
                "colores_custom = {'Abandono': '#e74c3c', 'Suspenso': '#f39c12', 'Aprobado': '#3498db', 'Sobresaliente': '#2ecc71'}\n",
                "\n",
                "sns.barplot(\n",
                "    data=weekly_breakdown, \n",
                "    x='dia_semana', \n",
                "    y='pct_click', # Usamos porcentaje para comparar hábitos, no volumen bruto\n",
                "    hue='Resultado', \n",
                "    hue_order=['Abandono', 'Suspenso', 'Aprobado', 'Sobresaliente'],\n",
                "    palette=colores_custom,\n",
                "    ax=ax3\n",
                ")\n",
                "\n",
                "ax3.set_title('Ritmo Semanal Normalizado: ¿Quién estudia los fines de semana?', fontsize=14)\n",
                "ax3.set_xlabel('Día del Ciclo (0-6)')\n",
                "ax3.set_ylabel('% de la Actividad Semanal del Grupo')\n",
                "ax3.set_xticklabels(['Día 1', 'Día 2', 'Día 3', 'Día 4', 'Día 5', 'Día 6', 'Día 7'])\n",
                "ax3.legend(title='Resultado', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Observaciones:** Es un problema serio que no podamos detectar el 40% de estudiantes que abandonan en el dia cero, necesitamos descubrir patrones antes del dia cero que nos permitan averiguar cosillas.\n",
                "\n",
                "Conclusión: \"Estudiar en fin de semana\" NO es predictor de éxito. (Rompe el mito del estudiante sacrificado).Decisión de Ingeniería: Esto valida al 100% nuestra decisión de hacer Agregación Semanal.\n",
                "Si hubiéramos visto patrones distintos, estaríamos obligados a alimentar a la IA con datos diarios (lunes, martes...).\n",
                "Como el patrón es idéntico, podemos sumar todo a la semana (clics_semana_X) y ahorramos un 85% de complejidad computacional sin perder ni una pizca de capacidad predictiva.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- OPERACIÓN RESCATE DÍA 0: Detectando patrones Pre-Arranque ---\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 1. EL FACTOR ANTELACIÓN (Date Registration)\n",
                "# ---------------------------------------------------------\n",
                "# date_registration suele ser negativo (días antes del curso).\n",
                "# Vamos a ver si los que se registran MUY pronto o MUY tarde abandonan más.\n",
                "sns.kdeplot(data=df_students[df_students['final_result'] == 'Withdrawn']['date_registration'], \n",
                "            label='Abandonos', color='red', fill=True, ax=axes[0])\n",
                "sns.kdeplot(data=df_students[df_students['final_result'] == 'Distinction']['date_registration'], \n",
                "            label='Sobresalientes', color='green', fill=True, ax=axes[0])\n",
                "axes[0].set_title('Antelación de Matrícula: ¿Influye cuándo te apuntas?', fontsize=12)\n",
                "axes[0].set_xlabel('Días antes del inicio (0 = Inicio)')\n",
                "axes[0].legend()\n",
                "axes[0].axvline(0, color='black', linestyle='--')\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 2. EL FACTOR \"MOCHILA\" (Intentos Previos)\n",
                "# ---------------------------------------------------------\n",
                "# ¿Los reincidentes abandonan más al principio?\n",
                "prev_attempts = df_students.groupby(['num_of_prev_attempts', 'final_result']).size().unstack(fill_value=0)\n",
                "prev_attempts_pct = prev_attempts.div(prev_attempts.sum(axis=1), axis=0) * 100\n",
                "# Solo mostramos la tasa de abandono\n",
                "prev_attempts_pct['Withdrawn'].plot(kind='bar', color='#e74c3c', ax=axes[1])\n",
                "axes[1].set_title('Reincidencia: Tasa de Abandono según Intentos Previos', fontsize=12)\n",
                "axes[1].set_ylabel('% de Abandonos')\n",
                "axes[1].set_xlabel('Número de Intentos Previos')\n",
                "\n",
                "# ---------------------------------------------------------\n",
                "# 3. EL MIEDO ESCÉNICO (Actividad Pre-Curso)\n",
                "# ---------------------------------------------------------\n",
                "# Calculamos si tuvieron actividad ANTES del día 0\n",
                "pre_clicks = df_interactions[df_interactions['date'] < 0].groupby('id_student')['sum_click'].sum().reset_index()\n",
                "pre_clicks.rename(columns={'sum_click': 'pre_clicks'}, inplace=True)\n",
                "\n",
                "# Unimos con estudiantes (left join para tener a los que tienen 0 clics)\n",
                "std_pre = df_students.merge(pre_clicks, on='id_student', how='left').fillna(0)\n",
                "\n",
                "# Clasificamos: ¿Hizo Clics Pre-Curso? SI / NO\n",
                "std_pre['Investigated_Platform'] = std_pre['pre_clicks'] > 0\n",
                "# Vemos tasa de abandono según si investigaron o no\n",
                "curiosity_gap = std_pre.groupby(['Investigated_Platform', 'final_result']).size().unstack()\n",
                "curiosity_gap_pct = curiosity_gap.div(curiosity_gap.sum(axis=1), axis=0) * 100\n",
                "\n",
                "curiosity_gap_pct[['Withdrawn', 'Fail', 'Pass', 'Distinction']].plot(kind='bar', stacked=True, color=['#e74c3c', '#f39c12', '#3498db', '#2ecc71'], ax=axes[2])\n",
                "axes[2].set_title('Curiosidad: ¿Entraron antes de empezar?', fontsize=12)\n",
                "axes[2].set_xticklabels(['No (Entraron el día 0 o nunca)', 'Sí (Investigaron antes)'], rotation=0)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "### **3. Análisis de Sesgos y Equidad Algorítmica (Fairness)**\n",
                "\n",
                "En el desarrollo de sistemas de aprendizaje automático aplicados a la educación, la **Equidad (Fairness)** es un requisito ético fundamental. Un modelo de IA puede perpetuar o incluso amplificar las desigualdades históricas si no se analizan y mitigan los sesgos presentes en los datos demográficos.\n",
                "\n",
                "En esta sección, se evalúa la distribución de la variable objetivo (`final_result`) en relación con los **atributos protegidos** y factores demográficos clave, con el fin de identificar posibles disparidades en los resultados educativos.\n",
                "\n",
                "#### **Dimensiones de Análisis de Sesgo:**\n",
                "1.  **Género (`gender`):** Evaluación de disparidades en el rendimiento académico entre hombres y mujeres.\n",
                "2.  **Discapacidad (`disability`):** Análisis de la brecha de éxito para estudiantes que requieren adaptaciones.\n",
                "3.  **Capital Cultural (`highest_education`):** Investigación del impacto del nivel educativo previo en la probabilidad de éxito actual.\n",
                "4.  **Entorno Socioeconómico (`imd_band`):** Relación entre la privación económica de la región de origen y los resultados académicos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Definimos los 3 atributos principales para comparar en serie\n",
                "protected_attributes = ['gender', 'disability', 'highest_education']\n",
                "\n",
                "# Creamos 1 fila con 3 columnas\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
                "\n",
                "for i, attr in enumerate(protected_attributes):\n",
                "    # Cálculo de porcentajes\n",
                "    props = (df_students.groupby(attr, observed=False)['final_result']\n",
                "             .value_counts(normalize=True)\n",
                "             .unstack() * 100)\n",
                "    \n",
                "    # Orden lógico para educación\n",
                "    if attr == 'highest_education':\n",
                "        order = ['No Formal quals', 'Lower Than A Level', 'A Level or Equivalent', 'HE Qualification', 'Post Graduate Qualification']\n",
                "        props = props.reindex([o for o in order if o in props.index])\n",
                "\n",
                "    # Plot (quitamos la leyenda individual con legend=False)\n",
                "    props.plot(kind='bar', stacked=True, ax=axes[i], colormap='viridis', alpha=0.8, legend=False)\n",
                "    \n",
                "    # Formateo de cada subplot\n",
                "    axes[i].set_title(f\"Por {attr.replace('_', ' ').capitalize()}\", fontsize=13, fontweight='bold')\n",
                "    axes[i].set_ylabel(\"Porcentaje (%)\" if i == 0 else \"\")\n",
                "    axes[i].set_xlabel(\"\")\n",
                "    axes[i].tick_params(axis='x', rotation=45)\n",
                "    axes[i].grid(axis='y', linestyle='--', alpha=0.3)\n",
                "\n",
                "# --- RECICLAJE DE LEYENDA ---\n",
                "# Tomamos los nombres de la leyenda del primer gráfico\n",
                "handles, labels = axes[0].get_legend_handles_labels()\n",
                "fig.legend(handles, labels, title=\"Resultado Final\", loc='center right', bbox_to_anchor=(1.1, 0.5))\n",
                "\n",
                "plt.suptitle(\"Análisis de Equidad: Brechas en Resultados Educativos\", fontsize=16, fontweight='bold', y=1.05)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### **Interpretación Crítica de los Sesgos Detectados**\n",
                "\n",
                "El análisis visual revela disparidades significativas que el modelo de aprendizaje profundo podría explotar de manera automática:\n",
                "\n",
                "*   **Sesgo de Capital Cultural:** Existe una correlación lineal entre el nivel educativo previo (`highest_education`) y la tasa de éxito (`Distinction`). Una red neuronal identificará este patrón como un atajo predictivo fuerte. El riesgo académico es que el modelo penalice a perfiles con menor formación previa, ignorando su progreso real durante el curso.\n",
                "*   **Brecha de Accesibilidad:** Los estudiantes con discapacidad presentan una franja de abandono (`Withdrawn`) ligeramente superior. Si el modelo utiliza esta variable sin procesar, podría generar alertas sesgadas que no consideren las barreras de accesibilidad externas al estudiante.\n",
                "*   **Equidad de Género:** En esta muestra, las distribuciones son notablemente similares, lo que sugiere que el atributo `gender` podría tener un peso neutral en la predicción, reduciendo el riesgo de sesgo por sexo.\n",
                "\n",
                "**Implicación para el Modelo:** Estos hallazgos justifican la necesidad de evaluar el modelo no solo mediante métricas globales (Accuracy/F1), sino también mediante **métricas de equidad (Fairness Metrics)**, asegurando que la precisión sea consistente en todos los grupos sociodemográficos."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
