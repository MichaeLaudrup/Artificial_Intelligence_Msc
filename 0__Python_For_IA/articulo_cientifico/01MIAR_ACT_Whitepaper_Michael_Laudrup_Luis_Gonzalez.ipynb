{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01MIAR - Actividad Whitepapers\n",
    "\n",
    "## Introducción:\n",
    "\n",
    "En el ámbito del desarrollo software cuando se intenta implementar una solución software no solo hay que prestar atención a llegar a una resolución concreta sino también a aplicar buenos patrones de desarrollo de código que permitan que sea más eficiente. En este documento se analiza y reflexiona sobre un artículo científico que aborda las principales malas prácticas que se llevan a cabo en el desarrollo de software en Python tanto para proyectos asociados al Machine Learning como para proyectos que no lo están.\n",
    "\n",
    "Posteriormente, se evaluará cómo el hecho de aplicar tanto los patrones de diseño ineficientes como los eficientes influyen en el coste temporal de la ejecución del código Python. \n",
    "\n",
    "## Objetivos:\n",
    "\n",
    "- Realizar un análisis reflexivo sobre el artículo científico y los resultados obtenidos.\n",
    "- Servir como guía para demostrar de manera empírica cómo utilizar ciertos patrones de desarrollo software mejora la eficiencia del código.\n",
    "- Ayudar a los desarrolladores a identificar y evitar el uso de prácticas poco recomendadas de desarrollo de software en Python.\n",
    "\n",
    "## Artículo científico fuente:\n",
    "\n",
    "El artículo científico sobre el que se basa este trabajo es el siguiente:\n",
    "\n",
    "- [François Belias, Leuson Da Silva, Foutse Khomh, Cyrine Zid (2025), Performance Smells in ML and Non-ML Python Projects: A Comparative Study]\n",
    " [https://arxiv.org/abs/2504.20224](https://arxiv.org/abs/2504.20224)\n",
    "\n",
    "La motivación de haber elegido este artículo científico es que aborda un tema muy relacionado con la asignatura, pudiendo servir como soporte y guía para principiantes en el mundo de la programación con Python, aprendiendo desde un primer momento a utilizar técnicas de desarrollo eficientes y sofisticadas como la comprensión de listas, diccionarios o conjuntos, así como asignaciones múltiples eficientes o comparaciones condicionales óptimas. \n",
    "\n",
    "Otro motivo de especial relevancia es que no solo se estudian los patrones incorrectos en código Python sino su distribución en proyectos de Machine learning frente a los que no lo son, distinguiendo incluso dentro de proyectos de Machine Learning en qué fases son más frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen y reflexión del artículo científico\n",
    "\n",
    "El artículo científico anteriormente citado analiza el impacto de las malas prácticas de rendimiento (performance smells) en código Python, especialmente comparando proyectos de Machine Learning (ML) con aquellos que no lo son (non-ML). A continuación, se plantean las tres principales preguntas a las que responde el estudio, sus respectivas respuestas y algunas conclusiones propias a partir de estas respuestas.\n",
    "\n",
    "### RQ1 ¿ Como se distribuyen las malas prácticas en código python en proyectos de machine Learning frente a proyectos que no lo son?\n",
    "\n",
    "La conclusión a la que llega el estudio es que en los proyectos de ML hay una mayor proporción de ineficiencias frente a los non-ML.. Desde mi punto de vista considero que tiene bastante sentido dado que en promedio los proyectos de ML suelen ser mucho más complejos, implican procesamiento de mayor volumen de datos y técnicas de programación más avanzadas\n",
    "\n",
    "### RQ2 ¿Qué diferentes tipos de implementación equivocada podemos encontrarnos en proyectos de Machine Learning?\n",
    "\n",
    "El artículo identifica un total de nueve performance smells en código Python. Estas malas prácticas afectan al rendimiento, la legibilidad y la eficiencia del software, y son fácilmente evitables mediante el uso de patrones idiomáticos del lenguaje. A continuación, se resumen las principales:\n",
    "\n",
    "| Concepto                     | Mala práctica                                             | Buena práctica                                                  |\n",
    "|-----------------------------|------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| List Comprehension          | Usar `for` con `append()` para construir listas            | Usar comprensiones de listas (`[x for x in ...]`)                |\n",
    "| Set Comprehension           | Usar `for` con `add()` para construir sets                 | Usar comprensiones de sets (`{x for x in ...}`)                  |\n",
    "| Dictionary Comprehension    | Usar `for` para asignar claves/valores a un diccionario    | Usar comprensiones de diccionarios (`{k: v for k, v in ...}`)    |\n",
    "| Chain Compare               | Comparaciones separadas con `and`                         | Comparaciones encadenadas (`a < b <= c`)                         |\n",
    "| Truth Value Test            | Comparar explícitamente con valores booleanos             | Usar la evaluación implícita de verdad (`if x:` en lugar de `if x != 0:`) |\n",
    "| For-Else                    | Uso de bandera (`flag`) para saber si se salió del `for`   | Usar directamente el bloque `else` del `for`                     |\n",
    "| Assign Multi Targets        | Asignaciones secuenciales una por una                     | Asignación múltiple (`a, b = b, a`)                              |\n",
    "| Star-in-Func-Call           | Llamar funciones con múltiples argumentos explícitos       | Usar `*args` para desempaquetar listas o rangos                  |\n",
    "| For-Multi Targets           | Iterar y luego extraer elementos manualmente (`x[0], x[1]`) | Desempaquetar directamente en el encabezado del bucle `for`     |\n",
    "\n",
    "### RQ3: ¿Comó estan distribuidos estas malas prácticas de desarrollo a lo largo de las diferentes fases de un proyecto de machine Learning?\n",
    "\n",
    "Se concluye que la fase de pre-procesamiento de datos es la fase de un proyecto de machine learning más susceptible de errores, acumulando la mayor parte de errores\n",
    "en proyectos de aprendizaje profundo. Desde mi perspectiva tiene bastante sentido dado que la fase de pre-procesamiento de datos es la que menos limitada está y la que \n",
    "más depende del factor humano. Es decir, una vez se elije un modelo de machine learning está muy estandarizado y acotado como debe ser usado este modelo y por ello\n",
    "siguiendo una metodología se es menos propenso a errores.\n",
    "\n",
    "Sin embargo, en la fase de procesamiento de datos, el factor humano tiene más relevancia y hay más libertad de desarrollo sin seguir una metodología específica por lo que \n",
    "la probabilidad de producir errores es más alta. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del coste temporal empírico\n",
    "\n",
    "Como complemento a lo aportado en el artículo científico el objetivo de este documento es enriquecer el conocimiento aportado haciendo un análisis del coste temporal empírico de aplicar unos determinados patrones de desarrollo de software frente a otros. Si llegamos a las mismas conclusiones de que a pequeña escala es más eficiente desarrollar de una manera que de otra, podremos concluir que esto en procesamientos que implican dimensiones mucho mayores del tamaño del problema a resolver implicarían costes elevadísimos tanto a diferentes niveles (computacional, temporal, energético, etc.)\n",
    "\n",
    "La manera en la que se ha decidido medir el tiempo empírico ha sido creando una función personalizada y reutilizable. Si bien otra alternativa hubiera sido utilizar funciones mágicas de Jupyter Notebook, se ha optado por usar herramientas más nativas de Python para tener más flexibilidad a la hora de decidir el número de ejecuciones y el formato en el que se imprime la información. Además de medir el tiempo de está manera, dado que estamos evaluando operaciones con coste temporales muy pequeños, se ha optado por ejecutar la operación 100 veces para obtener un caso promedio y así tener información más fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def control_time_execution(function, n = 100):\n",
    "    \"\"\" Imprime el tiempo de ejecución promedio de una función dada, ejecutándola n veces\n",
    "\n",
    "    Keyword arguments:\n",
    "    function -- función a medir\n",
    "    n -- número de iteraciones (default 100)\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    for _ in range(n):\n",
    "        start = time.perf_counter() * 1000000\n",
    "        function()\n",
    "        end = time.perf_counter() * 1000000\n",
    "        acc += ((end -start))\n",
    "    mean_time = acc / n\n",
    "    print(f\"[{function.__name__}] Tiempo de ejecución promedio en {n} iteraciones: {(mean_time):.2f} microsegundos\")\n",
    "    return mean_time\n",
    "\n",
    "def compare_two_functions(function_A, function_B, n = 100):\n",
    "    \"\"\" Compara el tiempo de ejecución de dos funciones y muestra cuál es más rápida\n",
    "\n",
    "    Keyword arguments:\n",
    "    function_A -- primera función a comparar\n",
    "    function_B -- segunda función a comparar\n",
    "    n -- número de iteraciones (default 100)\n",
    "    \"\"\"\n",
    "    t1 = control_time_execution(function_A, n)\n",
    "    t2 = control_time_execution(function_B, n)\n",
    "    if t1 > t2:\n",
    "        porcentaje = (t1 - t2) / t1 * 100\n",
    "        print(f'La función {function_B.__name__} es más rápida que {function_A.__name__}, con una disminución del tiempo de ejecución del {porcentaje:.2f}%.')\n",
    "    else:\n",
    "        porcentaje = (t2 - t1) / t2 * 100\n",
    "        print(f'La función {function_A.__name__} es más rápida que {function_B.__name__}, con una disminución del tiempo de ejecución del {porcentaje:.2f}%.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué malas prácticas se van a examinar? \n",
    "\n",
    "Se han seleccionado un subconjunto representativo de los \"code smells\", concretamente:\n",
    "\n",
    "- Comprensiones de listas y diccionarios.\n",
    "- Intercambio de variables : Este \"code smell\" es el que más se ha encontrado en los proyectos de machine Learning.\n",
    "- Condiciones explícitas en contraste con implicitas.\n",
    "\n",
    "### Comprensiones\n",
    "\n",
    "Las comprensiones son una forma concisa, elegante y más eficiente de crear estructuras de datos como listas, conjuntos y diccionarios usando una sola línea de código, en lugar de usar bucles tradicionales. En el siguiente fragmento de código vamos a crear un listado, conjunto y diccionario de 100.000 elementos contrastando el coste temporal empiríco de usar Comprensiones frente a métodos iterativos más tradicionales. \n",
    "\n",
    "#### Listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iterative_list_generator] Tiempo de ejecución promedio en 100 iteraciones: 4072.68 microsegundos\n",
      "[comprehension_list_generator] Tiempo de ejecución promedio en 100 iteraciones: 2342.32 microsegundos\n",
      "La función comprehension_list_generator es más rápida que iterative_list_generator, con una disminución del tiempo de ejecución del 42.49%.\n"
     ]
    }
   ],
   "source": [
    "def iterative_list_generator():\n",
    "    iterative_list = []\n",
    "    for el in range(100000):\n",
    "        iterative_list.append(el)\n",
    "    return iterative_list\n",
    "\n",
    "def comprehension_list_generator():\n",
    "   return [el for el in range(100000)]\n",
    "\n",
    "compare_two_functions(iterative_list_generator,  comprehension_list_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reforzar está idea si analizamos el resumen del artículo \"Python Functional Programming: Study of List Comprehensions and Lambda Functions Performance and Change-Proneness Risk\" [1] que dice que en general el uso de listas de comprensión es mejor que usar bucles for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iterative_dict_generator] Tiempo de ejecución promedio en 100 iteraciones: 6183.96 microsegundos\n",
      "[comprehension_dict_generator] Tiempo de ejecución promedio en 100 iteraciones: 5862.59 microsegundos\n",
      "La función comprehension_dict_generator es más rápida que iterative_dict_generator, con una disminución del tiempo de ejecución del 5.20%.\n"
     ]
    }
   ],
   "source": [
    "def iterative_dict_generator():\n",
    "    iterative_dict = {}\n",
    "    for el in range(100000):\n",
    "        iterative_dict[el] = el\n",
    "    return iterative_dict\n",
    "\n",
    "def comprehension_dict_generator():\n",
    "    return {el: el for el in range(100000)}\n",
    "\n",
    "compare_two_functions(iterative_dict_generator, comprehension_dict_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asignación de múltiples valores\n",
    "\n",
    "En la implementación de código es muy común encontrarse con el uso de variables auxiliares para realizar intercambios de valores entre variables. Python ofrece una manera más eficiente de desarrollar esta operación. En la función \"multiple_assignments\" veremos una manera más rudimentaria de implementar este intercambio de valores; sin embargo, en \"multiple_assignments_optimized\" vemos que el intercambio es más compacto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[multiple_assignments] Tiempo de ejecución promedio en 1000 iteraciones: 553.01 microsegundos\n",
      "[multiple_assignments_optimized] Tiempo de ejecución promedio en 1000 iteraciones: 505.93 microsegundos\n",
      "La función multiple_assignments_optimized es más rápida que multiple_assignments, con una disminución del tiempo de ejecución del 8.51%.\n"
     ]
    }
   ],
   "source": [
    "def multiple_assignments():\n",
    "    lst = [1, 2]\n",
    "    for _ in range(10000):\n",
    "        aux = lst[0]\n",
    "        lst[0] = lst[1]\n",
    "        lst[1] = aux\n",
    "    return lst\n",
    "\n",
    "def multiple_assignments_optimized():\n",
    "    lst = [1, 2]\n",
    "    for _ in range(10000):\n",
    "        lst[0], lst[1] = lst[1], lst[0]\n",
    "    return lst\n",
    "\n",
    "compare_two_functions(multiple_assignments, multiple_assignments_optimized, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión explicita de condiciones\n",
    "\n",
    "En este caso, la función \"explicit_truth_value_test\" hace una revisión más explícita de una condición, mientras que \"implicit_truth_value_test\" hace una revisión más implícita, aplicando con ello mejores prácticas de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[explicit_truth_value_test] Tiempo de ejecución promedio en 100 iteraciones: 3377.84 microsegundos\n",
      "[implicit_truth_value_test] Tiempo de ejecución promedio en 100 iteraciones: 2735.67 microsegundos\n",
      "La función implicit_truth_value_test es más rápida que explicit_truth_value_test, con una disminución del tiempo de ejecución del 19.01%.\n"
     ]
    }
   ],
   "source": [
    "def explicit_truth_value_test():\n",
    "    a = ''\n",
    "    for n in range(100000):\n",
    "        if n % 2 != 0:\n",
    "            a = 'even'\n",
    "        else:\n",
    "            a = 'odd'\n",
    "    return a\n",
    "\n",
    "def implicit_truth_value_test():\n",
    "    a = ''\n",
    "    for n in range(100000):\n",
    "        if n % 2:\n",
    "            a = 'even'\n",
    "        else:\n",
    "            a = 'odd'\n",
    "\n",
    "compare_two_functions(explicit_truth_value_test, implicit_truth_value_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En la siguiente tabla podemos apreciar los tiempos empíricos obtenidos para un determinada ejecución de este notebook, poniendo énfasis en que estos tiempos pueden cambiar dependiendo del hardware, plataforma, sistema operativo, etc., donde se ejecute este notebook.\n",
    "\n",
    "| Prueba                              | Método tradicional (µs) | Método eficiente (µs) | Mejora (%) |\n",
    "|--------------------------------------|-------------------------|-----------------------|------------|\n",
    "| Generación de listas                 | 4135.97                 | 2191.18               | 47.02      |\n",
    "| Generación de diccionarios           | 6183.96                 | 5862.59               | 5.20       |\n",
    "| Asignación múltiple                  | 553.01                  | 505.93                | 8.51       |\n",
    "| Truth Value Test (explícito vs impl.)| 3377.84                 | 2735.67               | 19.01      |\n",
    "\n",
    "podemos llegar a las siguiente conclusiones:\n",
    "\n",
    "- En general tal y como afirma el artículo cientifíco cuando implementamos software que sigue mejores prácticas Python hay una mejora del rendimiento y la velocidad empírica de ejecución.\n",
    "- Se ha apreciado que en el caso de comprensiones de listas la mejora es considerablemente alta, llegando a un 45-60% de mejora entre diferentes ejecuciones de este notebook, cabe subrayar que \n",
    "estamos hablando de Python nativo en este artículo y que probablemente si lo contrastamos con Numpy, esté último dará aún mejores rendimientos, dado que trabaja de manera mucho más optimizada\n",
    "listados de números en forma de numpy array. \n",
    "\n",
    "- La asignación múltiple es el fallo más común encontrado en los proyectos software de machine learning, si bien es el más abundante, no es el que más impacto tiene en el rendimiento, dado que su mejora\n",
    "oscila entre el 1% y el 9% entre diferentes ejecuciones de este mismo jupyternotebook, pero podemos concluir que aunque sea una mejora muy baja, cuando lo extrapolamos a escenarios con mucho más datos\n",
    "esta mejora se apreciará mucho más.\n",
    "\n",
    "En definitiva, la adopción de buenas prácticas de desarrollo en Python no solo contribuye a la eficiencia y legibilidad del código, sino que también puede suponer una diferencia significativa en proyectos reales donde el volumen de datos y la complejidad de los procesos son mucho mayores. Implementar estos patrones desde las primeras fases del desarrollo permite construir soluciones más robustas, escalables y sostenibles, optimizando recursos y facilitando el mantenimiento a largo plazo. Por tanto, invertir en la calidad del código es invertir en el éxito y la competitividad de los proyectos de inteligencia artificial y ciencia de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [1] [ François Philippe Ossim Belias (2022), Python Functional Programming: Study of List Comprehensions and Lambda Functions Performance and Change-Proneness Risk]\n",
    " [https://publications.polymtl.ca/10764/](https://publications.polymtl.ca/10764/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
